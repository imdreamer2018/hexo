title: Tensorflow学习—什么是过拟合以及dropout解决过拟合问题
author: 追梦人

toc: true

tags:

- MachineLearning

- tensorflow

- overfitting

- dropout

  categories: []
  date: 2018-04-19 10:25:00


---

# 什么是过拟合以及dropout解决过拟合问题

此教材来自[莫凡Python](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/)，本文旨在分享机器学习学习知识，如有侵权，可联系本人下架文章。

今天我们会来聊聊机器学习中的过拟合 overfitting 现象, 和解决过拟合的方法.

**注: 本文不会涉及数学推导. 大家可以在很多其他地方找到优秀的数学推导文章.**

<!--more-->

## 1、什么是过拟合(overfitting)

### 1.1 过于自负

![](http://imgss.lovebingzi.com/overfitting/overfitting1.png)

在细说之前, 我们先用实际生活中的一个例子来比喻一下过拟合现象. 说白了, 就是机器学习模型于自信. 已经到了自负的阶段了. 那自负的坏处, 大家也知道, 就是在自己的小圈子里表现非凡, 不过在现实的大圈子里却往往处处碰壁. 所以在这个简介里, 我们把自负和过拟合画上等号.

### 1.2 回归分类的过拟合

![](http://imgss.lovebingzi.com/overfitting/overfitting2.png)

机器学习模型的自负又表现在哪些方面呢. 这里是一些数据. 如果要你画一条线来描述这些数据, 大多数人都会这么画. 对, 这条线也是我们希望机器也能学出来的一条用来总结这些数据的线. 这时蓝线与数据的总误差可能是10. 可是有时候, 机器过于纠结这误差值, 他想把误差减到更小, 来完成他对这一批数据的学习使命. 所以, 他学到的可能会变成这样 . 它几乎经过了每一个数据点, 这样, 误差值会更小 . 可是误差越小就真的好吗? 看来我们的模型还是太天真了. 当我拿这个模型运用在现实中的时候, 他的自负就体现出来. 小二, 来一打现实数据 . 这时, 之前误差大的蓝线误差基本保持不变 .误差小的 红线误差值突然飙高 , 自负的红线再也骄傲不起来, 因为他不能成功的表达除了训练数据以外的其他数据. 这就叫做**过拟合. Overfitting.**

![](http://imgss.lovebingzi.com/overfitting/overfitting3.png)

### 1.3 解决方法

![](http://imgss.lovebingzi.com/overfitting/overfitting4.png)

**方法一**: 增加数据量, 大部分过拟合产生的原因是因为数据量太少了. 如果我们有成千上万的数据, 红线也会慢慢被拉直, 变得没那么扭曲 . 

**方法二:**

![](http://imgss.lovebingzi.com/overfitting/overfitting5.png)

运用正规化. L1, l2 regularization等等, 这些方法适用于大多数的机器学习, 包括神经网络. 他们的做法大同小异, 我们简化机器学习的关键公式为 y=Wx . W为机器需要学习到的各种参数. 在过拟合中, W 的值往往变化得特别大或特别小. 为了不让W变化太大, 我们在计算误差上做些手脚. 原始的 cost 误差是这样计算, cost = 预测值-真实值的平方. 如果 W 变得太大, 我们就让 cost 也跟着变大, 变成一种惩罚机制. 所以我们把 W 自己考虑进来. 这里 abs 是绝对值. 这一种形式的 正规化, 叫做 l1 正规化. L2 正规化和 l1 类似, 只是绝对值换成了平方. 其他的l3, l4 也都是换成了立方和4次方等等. 形式类似. 用这些方法,我们就能保证让学出来的线条不会过于扭曲.

![](http://imgss.lovebingzi.com/overfitting/overfitting6.png)

还有一种专门用在神经网络的正规化的方法, 叫作 dropout. 在训练的时候, 我们随机忽略掉一些神经元和神经联结 , 是这个神经网络变得”不完整”. 用一个不完整的神经网络训练一次.

到第二次再随机忽略另一些, 变成另一个不完整的神经网络. 有了这些随机 drop 掉的规则, 我们可以想象其实每次训练的时候, 我们都让每一次预测结果都不会依赖于其中某部分特定的神经元. 像l1, l2正规化一样, 过度依赖的 W , 也就是训练参数的数值会很大, l1, l2会惩罚这些大的 参数. Dropout 的做法是从根本上让神经网络没机会过度依赖.

## 2、dropout解决overfitting

### 2.1 回顾过拟合问题

Overfitting 也被称为过度学习，过度拟合。 它是机器学习中常见的问题。 举个Classification（分类）的例子。



![](http://imgss.lovebingzi.com/overfitting/5_02_1.png)

图中黑色曲线是正常模型，绿色曲线就是overfitting模型。尽管绿色曲线很精确的区分了所有的训练数据，但是并没有描述数据的整体特征，对新测试数据的适应性较差。

举个Regression (回归)的例子，

![](http://imgss.lovebingzi.com/overfitting/5_02_2.png)

第三条曲线存在overfitting问题，尽管它经过了所有的训练点，但是不能很好的反应数据的趋势，预测能力严重不足。 TensorFlow提供了强大的dropout方法来解决overfitting问题。

### 2.2 什么是dropout

我们知道，典型的神经网络其训练流程是将输入通过网络进行正向传导，然后将误差进行反向传播。Dropout就是针对这一过程之中，随机地删除隐藏层的部分单元，进行上述过程。

综合而言，上述过程可以分步骤为：

1. 随机删除网络中的一些隐藏神经元，保持输入输出神经元不变；
2. 将输入通过修改后的网络进行前向传播，然后将误差通过修改后的网络进行反向传播；
3. 对于另外一批的训练样本，重复上述操作

### 2.3 Dropout作用分析

从Hinton的原文以及后续的大量实验论证发现，**dropout可以比较有效地减轻过拟合的发生，一定程度上达到了正则化的效果**。

论其原因而言，主要可以分为两个方面：

1. 达到了一种Vote的作用。对于全连接神经网络而言，我们用相同的数据去训练5个不同的神经网络可能会得到多个不同的结果，我们可以通过一种vote机制来决定多票者胜出，因此相对而言提升了网络的精度与鲁棒性。同理，对于单个神经网络而言，如果我们将其进行分批，虽然不同的网络可能会产生不同程度的过拟合，但是将其公用一个损失函数，相当于对其同时进行了优化，取了平均，因此可以较为有效地防止过拟合的发生。
2. 减少神经元之间复杂的共适应性。当隐藏层神经元被随机删除之后，使得全连接网络具有了一定的稀疏化，从而有效地减轻了不同特征的协同效应。也就是说，有些特征可能会依赖于固定关系的隐含节点的共同作用，而通过Dropout的话，就有效地组织了某些特征在其他特征存在下才有效果的情况，增加了神经网络的鲁棒性。

### 2.4 当前Dropout的使用情况

当前Dropout被大量利用于全连接网络，而且一般人为设置为0.5或者0.3，而在卷积隐藏层由于卷积自身的稀疏化以及稀疏化的ReLu函数的大量使用等原因，Dropout策略在卷积隐藏层中使用较少。

总体而言，Dropout是一个超参，需要根据具体的网路，具体的应用领域进行尝试。

![](http://imgss.lovebingzi.com/overfitting/dropout.gif)