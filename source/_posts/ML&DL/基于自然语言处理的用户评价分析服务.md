title: 基于自然语言处理的用户评价分析服务
author: 追梦人

toc: true

tags:

  - python
  - MachineLearning
  - DeepLearning
  - NLP
categories: []
date: 2019-03-31 21:11:00

---

# 使用Python爬虫，爬取门户网站用户评价数据，基于nlp处理用户评价。

前两天，锁哥找我想不想做个兼职，我说什么兼职，他说帮别人做bysj，我说可以啊，难不难，他说不难。他负责爬取数据，我负责清洗数据并分析，刚开始觉得应该挺简单的，做的时候发现，这个数据清洗好麻烦。不说了，这两天都折腾在这了，下面码一下总结。

![Arhlfx.png](https://s2.ax1x.com/2019/03/31/Arhlfx.png)

<!-- more -->

## 程序运行流程

![ArII3t.png](https://s2.ax1x.com/2019/03/31/ArII3t.png)

## 爬虫部分

爬虫部分是锁哥从同程上爬的，我这边收到的文件是这样的。

![ArhTjU.png](https://s2.ax1x.com/2019/03/31/ArhTjU.png)

这里第一个是旅游地点，第二个是用户的评价，第三个是评价。

## 数据清洗

### 数据分类

由于这里涉及到不同的旅游景点，因为每个景点有每个景点的特色，把数据按景点来分来分析可能分析的结果好一点，然后我就将数据分开。

![ArhXNR.png](https://s2.ax1x.com/2019/03/31/ArhXNR.png)

![Arhj41.png](https://s2.ax1x.com/2019/03/31/Arhj41.png)

一共分类9类，其他的就不一一列举了。这里分类就比较简单了，直接用excel表格筛选就行了。

### 用户评论关键词提取

由于这里用户评论涉及到自然语言处理，这里我直接用了**百度的自然语言处理的接口**。这一步用到的是**评论观点提取**。

**评论观点抽取**

评论观点抽取接口用来提取一条评论句子的关注点和评论观点，并输出评论观点标签及评论观点极性。

```python
text = "很好的一次家庭旅行，原以为五一人多，取票会很困难，没想到单独设有网上订票取票窗口，真的很方便。景色很好，空气不错，爸妈都很喜欢，就是下山途中车子太多，有点小堵，不过全程都有景区工作人员指挥交通，很不错"

""" 调用评论观点抽取 """
client.commentTag(text);

""" 如果有可选参数 """
options = {}
options["type"] = 5

""" 带参数调用评论观点抽取 """
client.commentTag(text, options)
```

**评论观点抽取 请求参数详情**

| 参数名称 | 是否必选 | 类型   | 可选值范围                                                   | 说明                               |
| :------- | :------- | :----- | :----------------------------------------------------------- | :--------------------------------- |
| text     | 是       | string |                                                              | 评论内容（GBK编码），最大10240字节 |
| type     | 否       | string | 1 - 酒店 2 - KTV3 - 丽人 4 - 美食餐饮 5 - 旅游 6 - 健康 7 - 教育 8 - 商业 9 - 房产 10 - 汽车 11 - 生活 12 - 购物 13 - 3C | 评论行业类型，默认为4（餐饮美食）  |

**评论观点抽取 返回数据参数详情**

| 参数      | 类型   | 描述                                                |
| :-------- | :----- | :-------------------------------------------------- |
| log_id    | uint64 | 请求唯一标识码                                      |
| prop      | string | 匹配上的属性词                                      |
| adj       | string | 匹配上的描述词                                      |
| sentiment | int    | 该情感搭配的极性（0表示消极，1表示中性，2表示积极） |
| begin_pos | int    | 该情感搭配在句子中的开始位置                        |
| end_pos   | int    | 该情感搭配在句子中的结束位置                        |
| abstract  | string | 对应于该情感搭配的短句摘要                          |

**评论观点抽取 返回示例**

```json
{
    "items": [
        {
    'sentiment': 2,
    'abstract': '真的很方便<span></span>',
    'prop': '感觉',
    'begin_pos': 10,
    'end_pos': 10,
    'adj': '方便'
},
{
    'sentiment': 2,
    'abstract': '<span>景色很好</span>',
    'prop': '景色',
    'begin_pos': 0,
    'end_pos': 8,
    'adj': '美'
},
{
    'sentiment': 2,
    'abstract': '<span>空气不错</span>',
    'prop': '空气',
    'begin_pos': 0,
    'end_pos': 8,
    'adj': '清新'
},
{
    'sentiment': 2,
    'abstract': '爸妈都很喜欢<span></span>',
    'prop': '爸妈',
    'begin_pos': 12,
    'end_pos': 12,
    'adj': '喜欢'
},
{
    'sentiment': 2,
    'abstract': '就是下山途中<span>车子太多</span>',
    'prop': '车子',
    'begin_pos': 12,
    'end_pos': 20,
    'adj': '多'
},
{
    'sentiment': 2,
    'abstract': '32个赞<span></span>',
    'prop': '感觉',
    'begin_pos': 6,
    'end_pos': 6,
    'adj': '赞'
}
    ]
}
```

这里可以将关键词都提取出来，其中下面我们将利用到其中的参数`prop`和`adj`。例如上面提取到关键词`景色很好`，其中关键词属性为`景色`，关键词属性描述为`美`。下面我们将利用这两个属性。

### 关键词属性归类

上面提取到关键词属性和关键词属性描述。我们需要设置标签，这里我们将旅游的标签设置为五个**环境**，**风景**，**服务**，**交通**，**价格**。那么怎么讲关键词属性分类到这五个之中呢。这里我们还是利用了百度的自然语言处理的接口，利用**短文本相似分析**接口，我们获取关键词属性和标签的相似度。

**短文本相似度**

短文本相似度接口用来判断两个文本的相似度得分。

```python
text1 = "风景"

text2 = "景色"

""" 调用短文本相似度 """
client.simnet(text1, text2);

""" 如果有可选参数 """
options = {}
options["model"] = "CNN"

""" 带参数调用短文本相似度 """
client.simnet(text1, text2, options)
```

**短文本相似度 请求参数详情**

| 参数名称 | 是否必选 | 类型   | 可选值范围   | 说明                                  |
| :------- | :------- | :----- | :----------- | :------------------------------------ |
| text_1   | 是       | string |              | 待比较文本1（GBK编码），最大512字节   |
| text_2   | 是       | string |              | 待比较文本2（GBK编码），最大512字节   |
| model    | 否       | string | BOW CNN GRNN | 默认为"BOW"，可选"BOW"、"CNN"与"GRNN" |

**短文本相似度 返回数据参数详情**

| 参数    | 类型   | 描述               |
| :------ | :----- | :----------------- |
| log_id  | number | 请求唯一标识       |
| score   | number | 两个文本相似度得分 |
| texts   | array  | 输入文本           |
| +text_1 | string | 第一个短文本       |
| +text_2 | string | 第二个短文本       |

**短文本相似度 返回示例**

```json
{
    'log_id': 7599148415669066591,
    'texts': {
        'text_2': '景色',
        'text_1': '风景'
    },
    'score': 0.831879
}
```

这里返回到相似度为0.831879，可以准确将关键词属性分类到标签中，我这里设置了0.5的边界，当相似度大于0.5时才能判定为相关，否在不相关。

### 关键词属性描述情感分析

上一步我们将关键词属性分类到了应有的标签之中，现在还需要将关键词属性的描述进行情感分析，由于我们需要提取关键词的权值，方便我们进行最后一步的线性回归分析。所有我们利用百度的自然语言处理接口，**情感倾向分析**。

**情感倾向分析**

对包含主观观点信息的文本进行情感极性类别（积极、消极、中性）的判断，并给出相应的置信度。

```python
text = "美丽"

""" 调用情感倾向分析 """
client.sentimentClassify(text);
```

**情感倾向分析 请求参数详情**

| 参数名称 | 是否必选 | 类型   | 说明                                |
| :------- | :------- | :----- | :---------------------------------- |
| text     | 是       | string | 文本内容（GBK编码），最大102400字节 |

**情感倾向分析 返回数据参数详情**

| 参数           | 是否必须 | 类型   | 说明                                         |
| :------------- | :------- | :----- | :------------------------------------------- |
| text           | 是       | string | 输入的文本内容                               |
| items          | 是       | array  | 输入的词列表                                 |
| +sentiment     | 是       | number | 表示情感极性分类结果, 0:负向，1:中性，2:正向 |
| +confidence    | 是       | number | 表示分类的置信度                             |
| +positive_prob | 是       | number | 表示属于积极类别的概率                       |
| +negative_prob | 是       | number | 表示属于消极类别的概率                       |

**情感倾向分析 返回示例**

```json
{
    'log_id': 5534071773499402527,
    'text': '美丽',
    'items': [
        {
            'positive_prob': 0.71647,
            'confidence': 0.369932,
            'negative_prob': 0.28353,
            'sentiment': 2
        }
    ]
}
```

这里可以看到分析词美丽的情感倾向为正向，其中属于积极类别的概率为0.71647，这里我们将这个概率值设置为关键词属性描述的权值。

```python
#sentimentClassfy.py
def Classify(text):
    try:
        """ 调用情感倾向分析 """
        res = client.sentimentClassify(text)
        result = res['items'][0]
        return result['positive_prob']
    except:
        return 0
```

最后我们得到的两组文件，一组为清洗过后收集到的关键词属性，另外一组为清洗过后的关键词属性的权值。另外提一点的是，评价里面的**好评、中评、差评**的权值分别为**2、1、0**。

![ArImnS.png](https://s2.ax1x.com/2019/03/31/ArImnS.png)

![ArIn0g.png](https://s2.ax1x.com/2019/03/31/ArIn0g.png)

## 建立数据分析模型

根据上一步中我们提取到的关键词属性对于标签的权值，我们可以对此进行线性回归分析。这里我们建立多线性回归分析。其中我们采取到了**批梯度下降**和**正规方程**来训练数据。

### 数据预处理

由于上一步中，有一些数据是空的，我们将所有NAN设为0。

```python
path = './data/save_csv_score5.csv'
    #['环境','风景','服务','交通','价格']
    data = pd.read_csv(path,header=None,skiprows=[0],names=['Environment','Landscape','Service','Traffic','Price','Score'])
    cols = data.shape[1]
    #将所有nan设为0
    data = data.fillna(0)
    # 初始化变量
    data.insert(0, 'Ones', 1)
    X = data.iloc[:, 0:cols]
    y = data.iloc[:, cols:cols+1]
    # 转化为矩阵
    X = np.matrix(X.values)
    y = np.matrix(y.values)
    print(X, y)
    theta = np.matrix(np.array([0,0, 0, 0, 0, 0]))
```

### 批梯度下降

关于机器学习中批梯度下降的相关文档可以参考我的博客里面线性回归关于这方面的介绍。

```python
#ML_API.py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#代价函数
def computeCost(X,y,theta):
    inner = np.power(((X * theta.T)-y),2)
    return np.sum(inner) / (2 * len(X))

#批梯度下降函数
def gradientDescent(X,y,theta,alpha,iters):
    temp = np.matrix(np.zeros(theta.shape))
    parameters = int(theta.ravel().shape[1])
    cost = np.zeros(iters)

    for i in range(iters):
        error = (X * theta.T) -y

        for j in range(parameters):
            term = np.multiply(error,X[:,j])
            temp[0,j] = theta[0,j] - ((alpha / len(X)) * np.sum(term))

        theta = temp
        cost[i] = computeCost(X,y,theta)
    return theta,cost

#Cost训练进程图
def TraningEpoch(iters,cost):
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.plot(np.arange(iters), cost, 'r')
    ax.set_xlabel('Iterations')
    ax.set_ylabel('Cost')
    ax.set_title('Error vs. Training Epoch')
    plt.show()
```

**损失函数迭代**

![ArTjlq.png](https://s2.ax1x.com/2019/03/31/ArTjlq.png)

### 正规方程

关于正规方程的介绍也可以看博客中的教程。

```python
#正规方程
def normalEqn(X, y):
    theta = np.linalg.inv(X.T@X)@X.T@y#X.T@X等价于X.T.dot(X)
    return theta
```

### 训练结果

![ArT0Qx.png](https://s2.ax1x.com/2019/03/31/ArT0Qx.png)

![Agjj5n.png](https://s2.ax1x.com/2019/04/04/Agjj5n.png)

我这里将训练结果存到csv文件中，由于数据量太少，可能训练的结果不太准确，但是可以初步得到结果。这里标签对应的值越大，表明在游客的心中最为重要。比如这里基本上风景的权重最大，说明游客在游玩中认为风景最为重要。其次是环境因素和价格。服务和交通仅次其后。