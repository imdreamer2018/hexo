title: Deep Learning——Deep Convolutional Neural Networks

author: 追梦人

toc: true

categories: []

date: 2018-3-14 19:12:00

tags:

 - DeepLearning

 - Convolution
---

# 深度卷积神经网络

此教材来自吴恩达（Andrew Ng）<a href=""http://mooc.study.163.com/course/2001281004#/info>网易公开课</a>，本文旨在分享深度学习知识，如有侵权，可联系本人下架文章。
<!--more-->

![Andrew Ng](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/Andrew%20Ng.png)膜拜

## 一.残差网络(ResNets)

我们知道非常非常深的网络是很难训练的，因为存在**梯度消失**和**梯度爆炸**问题，所以我们可以利用跳远连接构建能够训练深度网络的**ResNets**，有时深度能到超过100层。

### 1.残差块(Residual block)

ResNets是由残差块构建的，**残差块**：这是一个两层神经网络 在L层进行激活,得到a[l+1]，再次进行激活 ，两层之后得到a[l+2]，计算过程是 从a[l]开始，首先进行线性激活，根据这个等式 通过a[l]算出z[l+1] ，即a[l]乘以权重矩阵 再加上偏差因子，然后通过ReLU非线性激活得到a[l+1] ，由a[l+1]等于g(z[l+1])计算得出，接着再次进行线性激活，依据的等式是这个 𝑧[𝑙+2] = 𝑊[𝑙+2]𝑎[𝑙+1] +𝑏[𝑙+2] ，最后根据这个等式再次进行ReLU非线性激活，得到的结果就是a[l+2]。换句话说 信息流从a[l]到a[l+2]，需要经过以上所有步骤，即这组网络层的主路径，在残差网络中有一点变化 ，我们将a[l]直接向后，拷贝到神经网络的深层，在ReLU非线性激活前加上a[l]，这是一条捷径（除了捷径 你还会听到另一个术语**跳远连接**），a[l]的信息直接到达神经网络的深层，不再沿着主路径传递，这就意味着最后这个等式𝑎[𝑙+2] = 𝑔(𝑧[𝑙+2])去掉了，取而代之的是另一个ReLU非线性函数𝑎[𝑙+2] = 𝑔(𝑧[𝑙+2]+ 𝑎[𝑙] )，也就是加上的这个a[l]产生了一个**残差块**。**残差网络**(ResNet)的发明者是何恺明，张翔宇，任少卿和孙剑，他们发现使用残差块能够训练更深的神经网络，所以构建一个ResNet网络就是通过将很多这样的残差块，堆积在一起 形成一个深度神经网络。

![Residual block](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/Residual%20block.png)

### 2.残差网络(Residual Network)

这并不是一个残差网络 而是一个普通网络，这个术语来自ResNet的论文 ，把它变成ResNet的方法是加上所有的跳远连接，或者说捷径，像这样，每两层增加一个捷径，构成一个残差块，如图所示 5个残差块连接在一起，构成一个残差网络。如果我们使用标准优化算法训练一个普通网络，比如说梯度下降，或者其他热门的优化算法，如果没有多余的残差 没有这些捷径，或者跳远连接，凭经验，**你会发现随着网络深度的加深，训练错误会先减少，然后增多，而理论上 随着网络深度的加深，应该训练得越来越好才对 ，也就是说 理论上网络深度越深越好，但实际上 如果没有残差网络，对于一个普通网络来说 深度越深意味着，用优化算法越难训练，随着网络深度的加深 训练错误会越来越多**。**但是有了ResNets就不一样了 即使网络再深，练的表现却不错 比如说出错误会减少，就算是训练深达100层的网络也不例外。但是对x的激活 或者这些中间的激活，能够达到网络的更深层，这种方式确实有助于解决梯度消失和梯度爆炸问题，让我们在训练更深网络的同时，又能保证良好的性能，ResNet确实在训练深度网络方面非常有效。**

至于为什么ResNets能有如此好的表现，请看下节。

![Residual Network](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/Residual%20Network.png)

### 3.残差网络为什么有如此好的表现？

我们来看一个例子 它解释了其中的原因，至少可以说明 如何在构建更深层次的ResNet网络的同时，还不降低它们在训练集上的效率，通常来讲 网络在训练集上表现好，才能在Hold-Out交叉验证集，或dev集和测试集上有好的表现，至少在训练集上训练好ResNet是第一步。

上节我们知道，一个网络深度越深 它在训练集上训练网络的效率会有所减弱，这也是有时候我们不希望加深网络的原因，而事实并非如此，至少在训练ResNet网络时 并不完全如此，举个例子，假设有一个大型神经网络 其输入为X，输出激活值a[l]，如果你想增加这个神经网络的深度，那么用Big NN表示 输出为a[l]，再给这个网络额外添加两层，依次添加两层，最后输出为a[l+2]，可以把这两层看作一个ResNet块，即具有近路连接的残差块，为了方便说明，假设我们在整个网络中使用ReLu激活函数，所有激活值都大于等于0，包括输入X的非零异常值，因为ReLu激活函数输出的数字要么是0 要么是正数，我们看一下a[l+2]的值，也就是表达式即a[l+2] =g(z[l+2]+a[l])，添加项a[l]是刚添加的跳远连接的输入，展开这个表达式 a[l+2]=g(W[l+2])a([l+1]+b[l+2]+a[l])，注意一点 如果使用L2正则化或权重衰减，它会压缩W[l+2]的值，如果对b应用权重衰减 亦可达到同样的效果，尽管实际应用中 你有时会对b应用权重衰减 有时不会，这里的W是关键项，如果W[l+2]=0，为方便起见 假设b也等于0，这几项就没有了 因为它们的值为0，最后等于g(a[l]) 也就是a[l]，因为我们假定使用ReLu激活函数，并且所有激活值都是负的，g(a[l]) 是应用于非负数的ReLu函数，所以a[l+2]等于a[l]，结果表明 **残差块学习这个恒等式函数残差块并不难，跳远连接使我们很容易得出a[l+2]=a[1]，这意味着 即使给神经网络增加了这两层，它的效率也并不逊色于更简单的神经网络 ，因为学习恒等函数对它来说很简单，尽管它多了两层 也只是把a[l]的值赋给a[l+2]，所以 给大型神经网络增加两层，不论是把残差块添加到神经网络的中间还是末端位置，都不会影响网络的表现，当然 我们的目标不仅仅是保持网络效率，还要提升它的效率，想象一下 如果这些隐层单元学到一些有用信息，那么它可能比学习恒等函数表现得更好，而这些不含有残差块或跳远连接的深度普通网络，情况就不一样了，当网络不断加深时，就算是选择用来学习恒等函数的参数都很困难，所以很多层最后的表现不但没有更好 反而更糟，我认为 残差网络起作用的主要原因就是，这些残差块学习恒等函数非常容易，你能确定网络性能不会受到影响 ，很多时候甚至可以提高效率，或者说至少不会降低网络效率，因此创建类似残差网络可以提升网络性能。**除此之外 关于残差网络 另一个值得探讨的细节是，假设z[l+2]与a[l]具有相同维度，所以ResNets使用了许多相同卷积过滤算法，所以这个a[l]的维度等于这个输出层的维度，因而实现了这个跳远连接，因为同一个卷积保留了维度，所以很容易得出这个短连接，并输出这两个相同维度的向量。

![why](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/why.png)

## 二、网络中的网络以及1×1 卷积

在架构内容设计方面，其中一个比较有帮助的想法是使用1x1的卷积，也许你会好奇 1x1的卷积能做什么呢，不就是乘以数字么，听上去挺好笑的，结果却并非如此。

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/1.png)

过滤器为1x1 这里是数字2，输入一张6x6x1的图片，然后对它做卷积 其过滤器大小为1x1x1，结果相当于把这个图片乘以数字2，所以前三个单元格分别是2 4 6，用1x1的过滤器进行卷积 似乎用处不大，只是对输入矩阵乘以某个数字，但这仅仅是对于6x6x1的信道图片来说 1x1卷积效果不佳，如果是一张6x6x32的图片，那么使用1x1过滤器进行卷积效果更好，具体来说 1x1卷积所实现的功能是，遍历这36个单元格，计算左图中32个数字和过滤器中32个数字的元素智能乘积，然后应用ReLU非线性函数，我们以其中一个单元格为例，它是这个输入层上的某个切片，用这36个数字乘以这个输入层上1x1的切片，得到一个实数，像这样把它画在输出中，这个1x1x32过滤器中的32个数字可以这样理解，一个神经元的输入是32个数字，乘以相同高度和宽度上某个切片上的32个数字，这32个数字具有不同信道，乘以32个权重 然后应用ReLU非线性函数，在这里输出相应的结果。一般来说 如果过滤器不止一个，而是多个，就好像有多个输入单元，其输入内容为一个切片上所有数字 ，输出结果是6x6x过滤器数量，所以1x1卷积可以从根本上理解为，这32个单元都应用了，一个全连接神经网络，全连接层的作用是输入32个数字，和过滤器数量，标记为nC[l+1]，在36个单元上重复此过程，输出结果是6x6x过滤器数量，以便在输入层上实施一个非平凡计算，这种方法通常称为1x1卷积，有时也被称为 Network in Network。在林敏 陈强和和杨学成的论文中有详细描述，虽然论文中关于架构的详细内容并没有得到广泛应用，但是1x1卷积或Network in Network这种理念，却很有影响力，多神经网络架构都受到它的影响。

举例：

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/2.png)

假设这是一个28x28x129的输入层 ，你可以使用池化层压缩它的高度和宽度，但是如果信道数量很大，该如何把它压缩为28x28x32维度的层呢，你可以用32个大小为1x1的过滤器，严格来讲 每个过滤器的大小都是1x1x192维，因为过滤器中信道的数量必须与输入层中信道的数量保持一致，因此使用32个过滤器，输出层为28x28x32，这就是压缩nC的方法，然而对于池化层 我只是压缩了这些层的高度和宽度。

## 三、谷歌Inception网络简介

当我们构建卷积层时，你要决定过滤器的大小究竟是1x3，3x3还是5x5，或者要不要添加池化层，而Inception网络的作用就是，代替你来做决定，虽然网络架构因此变得更加复杂，但网络表现却非常好,我们来了解一下其中的原理.

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/3.png)

例如 这是28x28x192维度的输入层，**Inception网络或Inception层的作用就是：代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层。**如果使用1x1卷积，输出结果会是28x28x某个值，假设输出为28x28x64，并且这里只有一个层，如果用3x3的过滤器，那么输出是28x28x128，然后我们把第二个值堆积到第一个值上，为了匹配维度，我们应用相同卷积，输出维度依然是28x28，和输入维度相同 即高度和宽度相同，这里是28x28x128，或许你会说，我希望提升网络的表现 用5x5过滤器或许会更好，我们不妨试一下，输出变成28x28x32，我们再次使用相同卷积 保持维度不变，或许你不想要卷积层，那就用池化操作，得到一些不同的输出结果 我们把它也堆积起来，这里池化输出是28x28x32，为了匹配所有维度，我们需要对最大化池使用padding，它是一种特殊的池化形式 ，因为如果输入的高度和宽度为28x28，则输出的相应维度也是28x28，然后再进行池化 padding不变 步幅为1，这个操作非常有意思。有了这样的Inception模块，你就可以输入某个量 ，因为它累加了所有数字，这里的最终输出为32+32+128+64 等于256，Inception模块的输入为28x28x192，提出者包括Christian Szegedy、刘伟、贾阳青、Pierre Sermanet，Scott Reed、Dragomir Anguelov、Dumitru Erhan，Vincent Vanhoucke 和Andrew Rabinovich。**基本思想是Inception网络不需要人为决定使用哪个过滤器 ，或是否需要池化 而是由网络自行确定这些参数 ，你可以给网络添加这些参数的所有可能值 ，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。**不难看出，我所描述的Incetption层有一个问题 就是计算代成本。

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/4.png)

这是一个28x28x192的输入块，执行一个5x5卷积 它有32个过滤器 输出为28x28x32，前一张幻灯片中 我用一个紫色的细长块表示，这里我用一个看起来更普通的蓝色块表示，我们来计算这个28x28x32输出的计算成本，因为输出有32个信道，每个过滤器大小为5x5x192，输出大小为28x28x32，所以要计算28x28x32个数字。对于输出中的每个数字来说，都需要执行5x5x192次乘法运算，所以乘法运算的总次数为，每个输出值所需的乘法运算次数，乘以输出值个数，把这些数相乘 结果等于1.2亿，即使在现代 用计算机执行1.2亿次乘法运算，成本也是相当高的，下一张幻灯片会介绍1x1卷积的应用，也就是我们上节课所学的，为了降低计算成本 我们用计算成本除以因子10，结果它从1.2亿减小到原来的十分之一。

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/5.png)

这有另外一种架构 其输入为28x28x192 输出为28x28x32，其结果是这样的 对于输入层，使用1x1卷积把输入值从192个信道减少到16个信道 ，然后对这个较小层，运行5x5卷积 得到最终输出28x28x32。请注意 输入和输出的维度依然相同，输入是28x28x192 输出是28x28x32 和上一页的相同，但我们要做的就是把左边这个大的输入层，压缩成这个较小的中间层，它只有16个信道 而不是192个，有时这被称为**瓶颈层，瓶颈通常是某个对象最小的部分。**假如你有这样一个玻璃瓶，这是瓶塞位置，瓶颈就是这个瓶子最小的部分。我们先缩小网络表示 然后再扩大它，接下来我们看看这个计算成本，应用1x1卷积，过滤器个数为16，每个过滤器大小为1x1x192，这两个维度相匹配，28x28x16这个层的计算成本是，输出28x28x192中的每个元素都做192次乘法，相乘结果约等于240万，那第二个卷积层的计算成本又是多少呢，这是它的输出 28x28x32，对每个输出值 应用一个5x5x16维度的过滤器，计算结果为1000万，所以所需乘法运算的总次数是，这两层的计算成本之和 也就是1240万，与上一张幻灯片中的值做比较，计算成本从1.2亿降到了，原来的十分之一 即1240万。

总结一下 如果你在构建神经网络层的时候，不想决定池化层是使用1x1 3x3还是5x5的过滤器，那inception模块就是最好的选择，我们可以应用各种类型的过滤器 只需把输出连接起来 ，之后我们讲到计算成本问题，我们学习了如何通过使用1x1卷积 ，来构建瓶颈层，从而大大降低计算成本。**你可能会问 仅仅大幅缩小表示层规模，会不会影响神经网络的性能 ，事实证明 只要合理构建瓶颈层，你既可以显著缩小表示层规模，又不会降低网络性能，从而大量节省了计算 ，这就是Inception模块的主要思想。**

## 四、Inception网络

上一节我们学习了谷歌Inception的基础模块，这一节我们将学习，如何将这些模块组合起来，构筑你自己的Inception网络。

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/6.png)

Inception模块会将之前层的激活或者输出，作为它的输入。这是一个28×28×192的输入，我们详细分析过的例子是，先通过一个1×1的层，再通过一个5×5的层，1×1的层可能有16个通道，而5×5的层的输出为，28×28 乘以32个通道，这是上一节讲到的我们处理的例子，为了在这个3×3的卷积层中，节省运算量，你也可以做相同的操作，这样的话3×3的层将会输出28×28×128，或许你还想将其直接通过一个1×1的卷积层，这时就不必在后面再跟一个1×1的层了，这样的话过程就只有一步，假设这个层的输出是28×28×64，最后是池化层，这里我们要做些有趣的事情，为了能在最后，将这些输出都连接起来，我们会使用same类型的，padding来池化，使得输出的高和宽依然是28×28，这样才能将它与其他输出连接起来，但注意 如果你进行了最大池化，即便用了 same padding，3x3的过滤器 stride为1，其输出将会是28×28×192，其通道数量或者说深度，与这里的输入相同，所以看起来它会有很多通道，我们实际上要做的，就是再加一个1×1的卷积层，去进行我们在1×1卷积层的视频里所介绍的操作，将通道的数量缩小，缩小到28×28×32，这样就避免了最后输出时，池化层占据所有的通道，最后 将这些方块，全都连接起来，在这过程中，把得到的各个层的通道都加起来，最后得到一个28×28×256的输出，这就是一个 Inception 模块。而 Inception 网络所做的，就是将这些模块都组合到一起。

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/9.png)

这是一张取自Szegety et al.的论文中，关于Inception网络的图片，你会发现图中有许多重复的模块，可能整张图看上去很复杂，但如果你只截取其中一个环节，就会发现这是在前一页ppt中所见的Inception模块，所以Inception网络是很多这些你学过的模块，在不同位置重复组成的网络，所以如果你理解了，之前所学的Inception模块，你就也能理解Inception网络。事实上，如果你读过论文的原文，你就会发现这里其实还有一些分支，所以这些分支有什么用呢，在网络的最后几层，通常称为全连接层，在它之后是一个softmax层，来做出预测，这些分支所做的，就是通过隐藏层，来做出预测，所以这其实是一个softmax输出，你应该把它看做，Inception网络的一个细节，它确保了即便是隐藏单元和中间层，也参与了特征计算，他们也能预测出图片的分类，它在Inception网络中，起到一种调整的效果，并且能防止网络发生过拟合。还有 这个特别的Inception网络，是由Google公司的作者所开发的它被叫做GoogLeNet，这个名字是为了向LeNet网络致敬。深度学习工作者对彼此的工作成果，有一种强烈的敬意。最后 有个有趣的事实，Inception网络这个名字又是缘何而来呢？

![[http://knowyourmeme.com/memes/we-need-to-go-deeper](http://knowyourmeme.com/memes/we-need-to-go-deeper)](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/8.png)

Inception的论文特地提到了这个梗，就是 "我们需要走得更深"，论文还引用了这个网址，链接到这幅图片上，如果你看过 Inception (盗梦空间) 这个电影，你应该能看懂这个梗，作者其实是通过它来表明了，要建立更深的神经网络的决心，他们正是这样，构建了 Inception，我想一般研究论文通常不会引用网络流行梗，但在这里显然很合适。

## 五、使用开源的实现方案

你现在已经学习了几个非常有效的神经网络和 ConvNet 构架，接下来我想与你分享几条如何使用它们的实用性建议，首先从使用开放源码的实现开始。事实证明很多神经网络，复杂细致 因而难以复制，因为一些参数调整的细节问题，例如学习率衰减等等，会影响性能，所以 我发现有些时候，甚至在顶尖大学，学习AI或者深度学习的博士生，也很难通过阅读别人研究论文，来复制他人的成果，幸运的是有很多深度学习的研究者，都习惯把自己的成果作为开发资源，放在像 GitHub 之类的网站上，当你自己编写代码时，我鼓励你考虑一下将您的代码贡献给开源社区，如果你看到一篇研究论文，想应用它的成果，你应该考虑做一件事，我经常做的就是在网络上寻找一个开源的实现，因为你如果能得到作者的实现，通常要比你从头开始，实现要快得多。虽然从零开始实现，肯定可以是一个很好的锻炼。如果你已经熟悉如何使用github，这一节对你来说可能，没什么必要或者没那么重要，但是如果你不习惯，从 GitHub 下载开源代码，让我来演示一下。

<video src="http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/1.mp4" controls="controls" style="max-width: 100%; display: block; margin-left: auto; margin-right: auto;">
your browser does not support the video tag
</video>

## 六、迁移学习

如果你要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开始，如果你下载别人，已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。计算机视觉的研究社区非常喜欢把许多数据集上传到网上，如果你听说过 比如ImageNet，或者MS COCO 或者Pascal类型的数据集，这些都是不同数据集的名字，这都是由大家上传到网上的，并且有大量的计算机视觉研究者，已经用这些数据集训练过他们的算法了，有时候这些训练过程需要花费好几周，并且需要很多的GPU，其他人已经做过了，并且经历了非常痛苦的，找最优的过程，这就意味着你可以下载，花费了别人好几周甚至几个月，而做出来的开源的权重参数，把它当做一个很好的初始化，用在你自己的神经网络上，用迁移学习把公共的数据集的知识，迁移到你自己的问题上个，让我们看一下怎么做。

![](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/10.png)

举个例子，假如说你要建立一个猫的检测器，用来检测你自己的宠物猫。比如网络上的Tigger是一个常见的猫的名字，Misty也是比较常见的猫的名字，假如你的两只猫叫Tigger和Misty，还有一种情况是 两者都不是，所以你现在有一个，三分类的问题，图片里是Tigger还是Misty或者都不是，我们忽略两只猫同时出现在一张图片里的情况，现在你可能没有Tigger或者Misty的大量的图片，所以你的训练集会很小，你该怎么办呢，我建议你从网上下载一些神经网络开源的实现，不仅把代码下载下来，也要把权重下载下来，有许多训练好的网络，你都可以下载，举个例子 ImageNet数据集，它有1000个不同的类别，因此这个网络会有一个Softmax单元，它可以输出1000个可能类别之一，你可以去掉这个Softmax层，创建你自己的Softmax单元，用来输出Tigger Misty neither三个类别，就网络而言，我建议你把所有的层都看作是冻结的，你冻结网络中所有层的参数，你只需要训练，和你的Softmax层有关的参数，这个Softmax层有三个可能的输出，Tigger Misty 或者都不是。通过使用其他人预训练的权重，你很可能得到很好的性能，即使只有一个小的数据集。幸运的是 大多数深度学习框架，都支持这种操作，事实上 取决于用的框架，它也许会有trainableParameter = 0这样的参数，对于这些前面的层 你可能会设置这个参数，为了不训练这些权重，有时候也会有freeze = 1这样的参数。不同的深度学习编程框架有不同的方式，允许你指定是否，训练特定层的权重。在这个例子中，你只需要训练softmax层的权重，把前面这些层的权重都冻结，另一个技巧，也许对一些情况有用，由于前面的层都冻结了，相当于一个固定的函数 不需要改变，因为你不需要改变它 也不训练它，取输入图像x，然后把它映射到这层的激活函数，所以这个能加速训练的技巧就是，如果我们先计算这一层，计算特征或者激活值，然后把它们存到硬盘里，你所做的就是用这个固定的函数，在这个神经网络的前半部分，取任意输入图像x，然后计算它的某个特征向量，这样你训练的就是一个很浅的softmax模型，用这个特征向量来做预测，对你的计算有用的一步就是提前计算你训练集中所有样本的这一层的激活值，然后储存到硬盘里，然后在此之上训练softmax分类器，所以 存储到硬盘，或者说预计算方法的优点，就是你不需要每次遍历训练集，再重新计算这个激活值了。

因此如果你的任务只有一个很小的数据集，你可以这样做。要是有一个更大的训练集怎么办呢？根据经验，如果你有一个更大的标定的数据集，也许你有大量的Tigger Misty的照片和这两种都不是，这种情况 你应该冻结更少的层，然后训练后面的层，如果你的输出层的类别不同，那么你需要构建自己的输出单元，Tigger Misty或者两者都不是三类别，有很多方式可以实现，你可以取后面几层，你可以取这几层的权重作为初始化，然后从这里开始梯度下降，或者你可以直接去掉这几层，换成你自己的隐藏单元，和你自己的softmax输出层，这些方法值得一试。**但是有一个规律，如果你有越多的数据，你需要冻结的层数越少，你能够训练的层数，就越多，这个理念就是 如果你有一个更大的数据集，也许有足够多的数据，那么不要单单训练一个softmax单元，而是考虑训练中等大小的网络，包含你最终要用的网络的后面几层。**最后 如果你有大量数据，你应该做的就是用开源的网络和它的权重，把整个的当做初始化，然后训练整个网络。再次注意 如果这是一个1000个节点的softmax，而你只有三个输出，你需要你自己的softmax输出层，来输出你要的标签，如果你有越多的标定的数据，或者越多的Tigger Misty，或者两者都不是的图片，你可以训练越多的层。极端情况下，你可以用下载的权重只作初始化，用他们代替随机初始化。

## 七、数据扩充

<video src="http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/2.mp4" controls="controls" style="max-width: 100%; display: block; margin-left: auto; margin-right: auto;">
your browser does not support the video tag
</video>

## 八、计算机视觉现状

深度学习已经成功地应用于计算机视觉，自然语言处理 语音识别 在线广告，物流还有许多其他问题，在计算机视觉的状态下 深度学习应用于计算机视觉的应用有一些独特之处，我将和你们分享一些我对计算机视觉的深入学习希望能帮助你们更好地驾驭文学和思想的集合，以及如何自己构建这些计算机视觉系统。

<video src="http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/3.mp4" controls="controls" style="max-width: 100%; display: block; margin-left: auto; margin-right: auto;">
your browser does not support the video tag
</video>

