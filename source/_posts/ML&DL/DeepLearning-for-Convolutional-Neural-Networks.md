title: Deep Learning——Convolutional Neural Networks
author: 追梦人
tags:
  - DeepLearning

  - Convolution


toc: true
categories: []

date: 2018-03-13 14:43:00

---



# 卷积神经网络

此教材来自吴恩达（Andrew Ng）<a href="http://mooc.study.163.com/course/2001281004#/info">网易公开课 </a>，本文旨在分享深度学习知识，如有侵权，可联系本人下架文章。
<!--more-->

![Andrew Ng](http://imgss.lovebingzi.com/Deep-Convolution-Neural-Networks/Andrew%20Ng.png)膜拜



## 一.计算机视觉

### 1.计算机视觉问题
当我们人类去辨别某种物体的时候，能够很容易的辨别出来，但是对于计算机而言却没那么容易，我们可以利用深度学习，来使计算机获取图片上的特征，来判断图片的物体时什么，当然深度学习也可以用于神经风格的转变，将两种不同类型的图片风格结合起来，还有用于物体的检测，判断这个物体是什么，距离是多少，大小是多少等等，在无人车上应用。
![Computer Vision Problems](/images/pasted-4.png)
### 2.大图片上的深度学习
我们知道越清晰的图片，它的大小就越大，有色彩的图片是又R G B三层所构成，越位清晰的图片，颜色矩阵就约为精密，照片就越清晰，矩阵的每个元素就像神经网络一样相互联系，当然如果我们直接去训练这些神经元素，会造成很大的Cpu消耗，所有在我们去处理神经元素时，我们需要去过滤神经元素的特征，提取一些重要特征，然后训练这些特征，最终能够得到我们想要的结果。那么如何检测这些特征呢？请看下一节
![upload successful](/images/pasted-5.png)
## 二.边缘检测示例
### 1.计算机视觉问题
上节说到，计算机的视觉和人的视觉不一样，但是我们可以提取图片的特征给计算机，进而让计算机产生视觉判断，首先由垂直，水平，45°，70°等等特征开始到人的器官特征识别，再到人脸的识别，其中有几千，几万甚至几百万的特征需要处理，这就需要计算机去训练这些特征。
![Computer Vision Problem](/images/pasted-8.png)
### 2.垂直边缘检测示例
例如我们有一张左边为白色，右边为灰色的图片，我们可以明显的看到这张图片中间有垂直的特征，这时我们需要一个过滤器来过滤这个矩阵，例如右边这个`3*3`的矩阵（这里`*`是数学里面的乘，图片中的`*`是卷积神经的过滤运算符号）就是一个垂直过滤器，**运算方法:** 
![](/images/pasted-7.png)
![运算方法](/images/pasted-6.png)
![Vertical edge detection examples](/images/pasted-1.png)
## 三.更多的边缘检测
### 1.垂直边缘检测
![Vertical edge detection examples](/images/pasted-1.png)
### 2.垂直与水平边缘检测
![Vertical and Horizontal Edge Detection](/images/pasted-2.png)
### 3.学习检测边缘
![Learning to detect edges](/images/pasted-3.png)
上述卷积神经过滤运算后，其实有两个缺点。**1.图片矩阵经过卷积神经过滤运算后矩阵的大小会越来越小，可能会造成某些特征值丢失。2.图片矩阵边缘，例如四边的角落，卷积神经过滤运算对这里的特征过滤较少，因为这里的过滤运算相比中间部分较少，可能造成特征提取不充分。**那么我们怎么去解决这两个问题呢？请看下一节！
## 四.Padding
### 1.图片矩阵添加Padding
为了解决上述两个缺点，可以在图片矩阵周围添加若干层padding，例如`6*6`图片矩阵加一层padding(padding的矩阵权值为0)后为`8*8`,经过卷积神经过滤运算后还是为`6*6`,这样就可以解决上述两个缺点。
![Padding](/images/pasted-9.png)
### 2.固态与相同卷积神经
当为固态卷积神经时，就不用添加padding，`n*n`  `*` `f*f`  -> `(n-f+1)*(n-f+1)`，例如`6*6` ` * ` `3*3` -> `4*4`。当为相同卷积神经时，`n+2p-f+1 = n`，计算p的值即可。
![Valid and Same convolutions](/images/pasted-10.png)
## 五.卷积步长
上述卷积神经过滤运算时，步长为1，所以每次仅移动一格，当然我们可以设置步长的大小s
![Strided convolution](/images/pasted-11.png)
**这样我们的过滤运算为：`n*n`  `*`  `f*f`  ->  `[(n+2p-f)/s+1]*[(n+2p-f)/s+1]`(这里的[]为向下取整)**
![Summary of convolutions](/images/pasted-12.png)
## 六.卷积神经中“卷”的体现之处
我们知道一张色彩图片由RGB三层组成，所以我们所说的卷积神经的“卷”的体现之处就在于有很多层。
**运算方法：原图片矩阵有多少层，过滤器就需要多少层，每一层对于每一层的过滤计算，然后将每一层的结果加起来，组成新的矩阵**
![Convolutions on RGB images](/images/pasted-13.png)
**过滤运算后的矩阵层数根据过滤器的个数决定，过滤器有几个，过滤运算后的矩阵就有几层**
![Multiple filters](/images/pasted-14.png)
## 七.简单卷积网络示例
### 1.简单卷积网络示例
![Example ConvNe](/images/pasted-15.png)
### 2.卷积网络中的层类型
一般经典卷积神经网络的层类型，由卷积神经层，池化层，全连接层组成。下面我们将讲解池化层与最大连接层。
![Types of layer in a convolutional network](/images/pasted-16.png)
## 八.池化层
### 1.最大池化层
选取每个方格的最大值
![ Max pooling](/images/pasted-17.png)
当然池化层跟卷积层一样也存在步长s，Padding。
![Max pooling](/images/pasted-18.png)
### 2.平均池化层
![Average pooling](/images/pasted-19.png)
## 九.卷积神经网络示例
这是一个经典的卷积神经网络示例，原图片矩阵->卷积过滤运算(conv1)->池化过滤运算(pool1)->卷积过滤运算(conv2)->池化过滤运算(pool2)->将得到的特征个数并排成一维向量，我们可以把平整化结果想象成像这样一个神经元集合，然后利用这400个单元构建下一层，这一层有120个单元，这就是我们的第一个全连接层（FC3），这400个单元与120个单元紧密相连，然后我们对这120个单元再添加一个全连接层，假设它含有84个单元（FC4）->用这84个单元填充一个softmax单元->output。**随着神经网络深度的加深 高度nH和宽度nW通常都会减少,而信道数量会增加**
![Neural network example](/images/pasted-20.png)
### 神经网络的激活值形状
**输入层没有参数，计算其它层的时候 ，试着自己算出激活值，这些都是网络中不同层的激活值形状和激活值大小，有几点要注意，第一 池化层和最大池化层没有参数，第二 卷积层的参数相对较少，其实许多参数都存在于神经网络的全连接层，观察可发现，随着神经网络的加深 激活值会逐渐变小，如果激活值下降太快 也会影响网络性能。**
![Neural network example](/images/pasted-21.png)
## 十.为什么使用卷积
和只用全连接层相比 卷积层的两个主要优势在于，**参数共享和稀疏连接**。举例说明一下，假设有一张32x32x3的纬度图片，假设用了6个大小为5x5的过滤器，输出维度为28x28x6，32x32x3=3072，28x28x6=4704，我们构建一个神经网络 其中一层含有3072个单元，下一层含有4074个单元，两层中的每个神经元彼此相连，然后计算权重矩阵，它等于3072x4704，约等于1400万，所以要训练的参数很多，然以现在的技术 我们可以用1400多万个参数来训练网络，因为这张32x32x3的图片非常小，练这么多参数没有问题，如果这是一张1000x1000的图片，重矩阵会变得非常大。
![Why convolutions](/images/pasted-23.png)
我们看看这个卷积层的参数数量，每个过滤器都是5x5，一个过滤器有25个参数 再加上偏差参数，那么每个过滤器就有26个参数 一共有6个过滤器，所以参数共计156个，参数数量还是很少，卷积网络映射这么少参数有两个原因，**参数共享：在图像的一部分中有用的特征检测器（如垂直边缘检测器）在图像的另一部分可能有用**。观察发现，特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其它区域，也就是说 如果你用一个3x3的过滤器检测垂直边缘，那么图片的左上角区域，以及旁边的各个区域都可以使用这个3x3的过滤器，每个特征检测器以及输出，都可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其它特征，它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征 例如提取脸上的眼睛，猫或者其它特征对象，即使减少参数个数，这9个参数也同样能计算出16个输出。直观感觉是 一个特征检测器 如垂直边缘检测器，用于检测图片左上角区域的特征，这个特征很可能也适用于，图片的右下角区域，因此 在计算图片的左上和右下角区域时，你不需要添加其它特征检测器。假如有一个这样的数据集，其左上角和右下角可能有不同分布，也可能稍有不同 但是很相似，整张图片共享特征检测器 提取效果也很好。卷积网络减少参数的第二种方法是**稀疏连接：在每一层中，每个输出值只依赖少量的输入**。解释一下，这个0是通过3x3的卷积计算得到的，它只依赖于这个3x3的输入单元格，右边这个输出单元，仅与36个输入特征中的9个相连接，而且 其它像素值，都不会对输出产生任何影响，这就是稀疏连接的概念。所以，神经网络可以通过这两种机制减少参数，以便于我们用更小的训练集来训练它，从而预防过度拟合。实际上 我们用同一个过滤器生成各层中，图片的所有像素值，希望网络通过自动学习变得更加健壮，以便更好地取得所期望的平移不变属性，这就是卷积或卷积网络在计算机视觉任务中，表现良好的原因
![Why convolutions](/images/pasted-22.png)
我们把这些层整合起来 看看如何训练这些网络,比如我们要构建一个猫咪检测器,我们有下面这个标记训练集,x表示一张图片,y^是二进制标记或某个重要标记,我们选定了一个卷积神经网络,输入图片 增加卷积层和池化层,然后添加全连接层 最后输出一个softmax 即y^,卷积层和全连接层,有不同的参数w和偏差b,我们可以用任何参数集合来定义代价函数,一个类似的那种代价函数，并随机初始化其参数w和b，CostJ等于神经网络对整个训练集的预测的损失总和，再除以m，所以训练神经网络 你要做的就是使用梯度下降法，或其它算法 例如含冲量的梯度下降，含RMSProp或其它因子的梯度下降，来优化神经网络中的所有参数，以减少代价函数J的值，通过上述操作你可以构建一个高效的猫咪检测器，或其它检测器。
![Putting it together](/images/pasted-24.png)