title: 可扩展隐私保护机器学习系统
author: 追梦人

toc: true

tags:

  - MachineLearning
  - Privacy-Preserving
  - Cryptology
categories: []
date: 2019-05-03 21:23:00

---

# 可扩展隐私保护机器学习系统

本文来自Yupeng Zhang在2017年信息安全旗舰会议《Security & Privacy》上的论文演讲，论文的题目是《安全机器学习：可扩展隐私保护机器学习系统》（SecureML: A System for Scalable Privacy-Preserving Machine Learning）。

论文链接：[Cryptology ePrint Archive: Report 2017/396](https://link.zhihu.com/?target=https%3A//eprint.iacr.org/2017/396)

以下是翻译后的原文。

<!-- more -->

## 摘要

机器学习在实践中被广泛用于为诸如图像处理，语音和文本识别的应用产生预测模型。在对从不同来源收集的大量数据进行培训时，这些模型更加准确。但是，海量数据收集引发了隐私问题。

在本文中，我们提出了新的和有效的隐私保护机器学习协议，用于线性回归，逻辑回归和使用随机梯度下降法的神经网络训练。我们的协议属于双服务器模型，其中数据所有者在两个非串通服务器之间分发其私有数据，这两个服务器使用安全的双方计算（2PC）在联合数据上训练各种模型。我们开发新技术以支持对共享十进制数的安全算术运算，并提出MPC友好的替代非线性函数，如sigmoid和softmax，它们优于以前的工作。

我们用C ++实现我们的系统。我们的实验证实，我们的协议比隐私保护线性和逻辑回归的现有技术实现快几个数量级，并且可以扩展到具有数千个特征的数百万个数据样本。我们还实施了第一个用于训练神经网络的隐私保护系统。

## 介绍

机器学习技术在实践中被广泛用于产生用于医学，银行业务，推荐服务，威胁分析和认证技术的预测模型。随着时间的推移收集的大量数据为旧问题提供了新的解决方案，深度学习的进步带来了语音，图像和文本识别方面的突破。

大型互联网公司收集用户的在线活动，以培训预测他们未来兴趣的推荐系统。来自不同医院和政府组织的健康数据可用于产生新的诊断模型，而金融公司和支付网络可以结合交易历史，商家数据和账户持有者信息来训练更准确的欺诈检测引擎。

虽然最近的技术进步使得能够更有效地存储，处理和计算大数据，但是组合来自不同来源的数据仍然是一项重要的挑战。竞争优势，隐私问题和法规以及围绕数据主权和管辖权的问题阻止了许多组织公开共享其数据。通过安全多方计算（MPC）进行隐私保护机器学习，通过允许不同实体在其联合数据上训练各种模型而不泄露结果之外的任何信息，提供了一种有前景的解决方案。

我们专注于训练线性回归，逻辑回归和神经网络模型的机器学习算法，并采用双服务器模型（更多细节见第3节），以前通过MPC保护隐私机器的工作常用[36，35,20]。在此模型中，在设置阶段，数据所有者（客户端）在两个非串通服务器之间处理，加密和/或秘密共享其数据。在计算阶段，两个服务器可以在客户的联合数据上训练各种模型，而无需学习训练模型之外的任何信息。

保护隐私线性回归[36,20]的现有技术解决方案比明文训练慢许多个数量级。先前实现中的低效率的主要来源是用于训练的大量计算发生在用于布尔电路的安全2PC内（例如，$$Yao​$$的乱码电路），其对表示为整数的十进制数执行算术运算。
众所周知，布尔电路不适合执行算术运算，但鉴于现有的定点或浮点乘法技术需要使用布尔电路最有效的位级操作，它们似乎是不可避免的。

在逻辑回归和神经网络的情况下，问题甚至更具挑战性，因为训练过程计算许多非线性激活函数的实例，例如在2PC内计算昂贵的sigmoid和softmax。实际上，我们不知道这两种训练算法的任何隐私保护实现。

### 我们的贡献

我们在上面讨论的双服务器模型中设计了用于隐私保护线性回归，逻辑回归和神经网络训练的新的有效协议，假设跨客户端对数据集进行任意划分。

我们的隐私保护线性回归协议比针对同一问题的现有技术解决方案高几个数量级。例如，对于具有100,000个样本和500个特征的数据集，并且在可比较的设置和实验环境中，我们的协议比[36,20]中实现的协议快1100-1300倍。此外，正如我们的实验所示，我们显着缩小了隐私保护和明文训练之间的差距。

我们还实现了第一个用于逻辑回归和神经网络训练的隐私保护协议，效率很高。例如，在大小为60,000且具有784个特征的数据集上，我们的隐私保护逻辑回归的总运行时间为29秒，而我们用于训练具有3层和266个神经元的神经网络的隐私保护协议在21,000s中运行。

我们的协议自然分为数据无关的离线阶段和更快的在线阶段。当排除离线阶段时，协议在明文培训方面更具竞争力。例如，对于具有60,000个样本和784个特征的数据集，并且在LAN设置中，线性回归协议在1.4s中运行，逻辑回归在8.9s中运行，神经网络训练在653.0s中运行。

**对共享十进制数的算术**。如前所述，先前工作的一个主要瓶颈是在安全2PC内部计算定点算术，例如乱码电路。考虑到训练所需的大量乘法，这非常昂贵。

定点加法相当简单。对于乘法，我们证明以下策略非常有效：将两个共享十进制数表示为有限域中的共享整数;使用离线生成的乘法三元组对共享整数执行乘法运算;让每一方截断其产品的份额，以便固定数量的位代表小数部分。我们证明，与定点算法相比，在从这些截断的份额重建时，产品的概率很高，在分数部分的最低有效位置最多为1位。我们对两个不同数据集MNIST和Arcene [6,1]的实验证实，当表示小数部分的位数时，小截断误差对训练模型的准确性没有影响（实际上精度与标准训练的准确度相匹配）足够大。因此，隐私保护线性回归的在线阶段不涉及任何加密操作，仅包括整数乘法和位移，而离线阶段包括生成必要的乘法三元组。我们的微基准测试表明，即使在考虑总时间（在线和离线组合）时，与使用乱码电路的定点乘法相比，我们的方法产生了4-8倍的改善。

**MPC友好的激活功能**。如前所述，逻辑回归和神经网络训练需要计算逻辑$\left(\frac{1}{1+e^{-x}}\right)​$和softmax$\left(\frac{e^{-x_{i}}}{\sum e^{-x_{i}}}\right)​$函数，这些函数在共享值上计算起来很昂贵。我们通过实验证明，使用低次多项式逼近逻辑函数是无效的。特别地，需要程度至少为10的多项式来使用逻辑函数来接近训练的准确性。我们提出了一种新的激活函数，它可以看作是两个RELU函数的总和（见图7），并使用一个小的乱码电路有效地计算。类似地，我们用RELU函数，添加和单个分区的组合替换softmax函数。我们使用MNIST和Arcene数据集的实验证实，使用这些新函数生成的模型的准确性与使用原始函数训练的模型匹配或非常接近。

然后，我们提出了一种用于在算术共享和$Yao$共享之间切换的定制解决方案，并且对于我们的特定计算，我们提出了通过最小化交互轮次和调用的不经意传输（OT）的数量来显着降低成本。我们在6.5节中的微基准测试表明，评估我们的新函数的时间比用高次多项式逼近逻辑函数要快得多。

我们使用相同的思想来安全地评估神经网络训练中使用的RELU函数。

**矢量化协议**。矢量化，即在矩阵和矢量上操作，对于明文训练的效率是至关重要的。我们将展示如何从共享设置中的相同矢量化技术中受益。例如，在我们的协议的离线阶段，包括生成许多乘法三元组，我们提出并实现两个基于线性同态加密（LHE）和不经意传输的解决方案。这些技术受到先前工作的启发（例如，[17]），但针对我们需要计算共享矩阵和向量的乘法的矢量化场景进行了优化。因此，我们的离线协议的复杂性比为每次乘法生成独立乘法三元组的简单方法要好得多。特别是，基于OT的乘法三元组生成的性能提高了4倍，基于LHE的生成提高了41-66倍。

在类似于[20]的不同安全模型中，我们还提出了一个更快的离线阶段，客户端可以帮助生成乘法三元组。这提供了比我们的标准设置更弱的安全性。特别是，它需要额外的假设，即服务器和客户端不会串通，即攻击者破坏服务器或客户端子集，但不会破坏两者。我们讨论了这种方法的优缺点，并将其性能与第5节中的标准方法进行了比较。

### 相关工作

早期关于隐私保护机器学习的工作主要集中在决策树[30]，k-均值聚类[27,13]，SVM分类[47,43]，线性回归[18,19,39]和逻辑回归[41]。这些论文提出了基于安全多方计算的解决方案，但似乎会产生高效率开销并且缺乏实施/评估 。

尼古拉琴科等人[36]使用LHE和乱码电路的组合在水平分区数据上呈现隐私保护线性回归协议，并在具有数百万个样本的数据集上对其进行评估。Gascon等人[20]将结果扩展到垂直分区数据并显示出改进的性能。然而，这两篇论文都减少了使用$Yao$的乱码电路协议解决线性系统的问题，这会在训练时间上引入很高的开销，并且不能推广到非线性模型。相比之下，我们使用随机梯度下降法，它可以训练非线性模型，如逻辑回归和神经网络。最近，Gilad-Bachrach等人[22]提出了一个安全数据交换的框架，并支持隐私保护线性回归作为一个应用程序。但是，只测试了小型数据集，并且·纯粹使用乱码电路实现协议，这不适用于较大的数据集。

Wu等人认为隐私保留逻辑回归[45]。他们建议使用多项式逼近逻辑函数，并使用LHE训练模型。然而，复杂度在近似多项式的程度上是指数的，并且正如我们将在实验中所示，与使用逻辑函数相比，模型的准确性降低。Aono等人[9]考虑一种不同的安全模型，其中不受信任的服务器收集并组合来自多个客户端的加密数据，并将其传输到可信客户端以在明文上训练模型。通过用2次多项式仔细逼近逻辑回归的代价函数，可以通过求解线性系统来计算最优模型。但是，在此设置中，聚合数据的明文泄露给训练模型的客户端。我们不知道在双服务器模型中使用实用的隐私保护逻辑回归系统的任何先前工作。

使用神经网络进行隐私保护机器学习更具挑战性。Shokri和Shmatikov [40]提出了一种解决方案，在这种解决方案中，两个服务器不是共享数据，而是在训练期间共享部分系数的变化。尽管该系统非常有效（根本不需要加密操作），但这些系数变化的泄漏并未得到充分理解，并且没有获得正式的安全保证。此外，他们的方法仅适用于水平分区数据，因为每个服务器需要能够在其部分上单独执行训练以获得系数变化。Gilad-Bachrach等人最近也研究了使用神经网络的隐私保护预测[21]。使用完全同态加密，神经网络模型可以对加密数据进行预测。在这种情况下，假设神经网络是在明文数据上训练的，并且该模型对于在另一方的私人数据上评估它的一方是已知的。

正交工作线考虑了机器学习算法的差异隐私[15,42,8]。在此设置中，服务器可以完全访问纯文本中的数据，但希望保证发布的模型不能用于推断培训期间使用的数据。差分私有机器学习中使用的常用技术是向数据或更新函数引入加性噪声（例如，[8]）。噪声的参数通常由数据的尺寸，机器学习算法的参数和安全要求预先确定，因此是与数据无关的。考虑到服务器总是可以根据公共参数生成噪声并将其直接添加到训练中的共享值中，我们的系统可以由这样的结构组成。通过这种方式，训练后的模型在重建后将是差异私有的，而所有数据在训练期间仍然保持私密。

## 预赛

### 机器学习

在本节中，我们将简要回顾本文考虑的机器学习算法：线性回归，逻辑回归和神经网络。我们提出的所有算法都是经典的，可以在标准的机器学习教科书中找到（例如，[25]）。

#### 线性回归

给定n个训练数据样本xi，每个训练数据样本xi包含d个特征和相应的输出标记yi，回归是学习函数g的统计过程，使得$g\left(\mathbf{x}_{i}\right) \approx y_{i}$。回归在现实生活中有很多应用。例如，在医学科学中，它用于学习疾病与代表性特征（例如年龄，体重，饮食习惯）之间的关系，并将其用于诊断目的。

在线性回归中，假设函数g是线性的，并且可以用系数向量**w**表示为xi的内积$g\left(\mathbf{x}_{i}\right)=\sum_{j=1}^{d} x_{i j} w_{j}=\mathbf{x}_{i} \cdot \mathbf{w}​$其中$x_{i j}\left(\text { resp. } w_{j}\right)​$是向量$\mathbf{x}_{i}(\text { resp. } \mathbf{w})​$中的第j个值，而·表示两个向量的内积。

> 通常引入噪点$b​$使得$g\left(x_{i}\right)=x_{i} \cdot w+b​$。然而，这可以通过为每个$x_{i}​$附加等于1的伪特征来容易地实现。为了简化表示法，我们假设$b​$已经嵌入到本文中

为了学习系数向量$\mathbf{w}$，定义成本函数$C(\mathbf{w})$并且通过优化$\operatorname{argmin}_{\mathbf{w}} C(\mathbf{w})$计算$\mathbf{w}$。在线性回归中，常用的代价函数是$C(\mathbf{w})=\frac{1}{n} \sum C_{i}(\mathbf{w})$），其中$C_{i}(\mathbf{w})=\frac{1}{2}\left(\mathbf{x}_{i} \cdot \mathbf{w}-y_{i}\right)^{2}$。

> 在岭回归中，惩罚项$\lambda\|\mathbf{w}\|^{2}$被添加到成本函数中以避免过度拟合，其中$λ$是正则化参数。本文中的协议以明显的方式支持这一点，并且为简单起见省略。

可以通过求解线性系统$\left(\mathbf{X}^{T} \times \mathbf{X}\right) \times \mathbf{w}=\mathbf{X}^{T} \times \mathbf{Y}​$来计算该优化问题的解，其中$\mathbf{X}​$是表示所有输入数据的$n×d​$矩阵，并且$\mathbf{Y}​$是用于输出标签的$n×1​$矩阵。然而，矩阵乘法$\mathbf{X}^{T} \times \mathbf{X}​$的复杂度为$O(nd^2)​$，求解线性系统的复杂度为$O(d^3)​$。由于其高复杂性，除了$n​$和$d​$的小值之外，它在实践中很少使用。

**随机梯度下降（SGD）** SGD是一种有效的近似算法，用于逐步逼近函数的局部最小值。由于上述线性回归的优化函数是凸的，因此SGD可证明地收敛于全局最小值并且在实践中通常非常快。此外，SGD可以推广用于逻辑回归和神经网络训练，其中对于相应的优化问题不存在封闭形式的解决方案。因此，SGD是在实践中训练此类模型的最常用方法，也是这项工作的主要重点。

SGD算法的工作原理如下：$\mathbf{w}​$被初始化为随机值或全0的向量。在每次迭代中，随机选择样本$\left(\mathbf{x}_{i}, y_{i}\right)​$并将系数$w_{j}​$更新为:
$$
w_{j} :=w_{j}-\alpha \frac{\partial C_{i}(\mathbf{w})}{\partial w_{j}} \tag{1}
$$
![EaOVud.png](https://s2.ax1x.com/2019/05/04/EaOVud.png)

<center>图1：（a）逻辑函数 （b）神经网络的一个例子</center>

其中$α$是学习速率，定义在每次迭代中向最小值移动的幅度。代替线性回归的代价函数，公式变为$w_{j} :=w_{j}-\alpha\left(\mathbf{x}_{i} \cdot \mathbf{w}-y_{i}\right) x_{i j}$。计算预测输出$y_{i}^{*}=\mathbf{x}_{i} \cdot \mathbf{w}$的相位称为前向传播，计算变化$\alpha\left(y_{i}^{*}-y_{i}\right) x_{i j}$的相位称为后向传播。

**小批量**。实际上，不是每次迭代选择一个数据样本，而是随机选择一小批样本，并通过平均当前$\mathbf{w}​$上所有样本的偏导数来更新$\mathbf{w}​$。我们用$B​$表示在小批量中选择的一组索引。这称为小批量SGD和$| B |​$ 表示小批量大小，通常在2到200之间。小批量的好处是可以使用矢量化库来加速计算，使得一个小批量的计算时间比运行$| B |​$快得多。迭代没有小批量。此外，通过小批量，$\mathbf{w}​$可以更平滑，更快速地收敛。使用小批量，更新功能可以以矢量化形式表示：
$$
\mathbf{w} :=\mathbf{w}-\frac{1}{|B|} \alpha \mathbf{X}_{B}^{T} \times\left(\mathbf{X}_{B} \times \mathbf{w}-\mathbf{Y}_{B}\right) \tag{2}
$$
$\mathbf{X}_{B}$和$\mathbf{Y}_{B}$是使用B中的索引选择的$\mathbf{X}$和$\mathbf{Y}$的$B \times d$和$B \times 1$子矩阵，表示$| B |$。迭代中的数据和标签样本。这里$\mathbf{w}$被视为列向量。

**学习率调整**。如果学习率$α​$太大，则SGD的结果可能偏离最小值。因此，测试数据集用于测试当前$\mathbf{w}​$的准确性。$\mathbf{w}​$的内积和测试数据集中的每个数据样本被计算为预测，并与相应的标签进行比较。准确度是测试数据集上正确预测的百分比。如果准确度在下降，则学习率会降低，培训将以新的学习率开始。为了平衡测试所花费的开销，通常的做法是对所有训练样本进行混洗，并在每次迭代中按顺序选择小批量，直到所有样本都使用一次。这被称为一个时代。在一个时期之后，测试当前$\mathbf{w}​$的准确度。此时，如果准确度降低，则学习率降低一半并且训练开始;否则，数据将被重新洗牌，并执行下一个训练时期。

**终止**。当与前一时期相比精确度的差异低于小阈值时，$\mathbf{w}​$被视为已收敛到最小值并且算法终止。我们将模型训练为$E​$的时期数表示，并将迭代总数表示为$t​$。请注意，我们有以下关系：$n \cdot E=|B| \cdot t​$

#### 逻辑回归

在具有两个类分类问题中，输出标签y是二进制的。例如，鉴于一些医学特征，我们有兴趣预测患者是健康还是生病。在这种情况下，最好将预测的输出限制在0和1之间。因此，激活函数f应用于内积之上，并且关系表示为：$g\left(\mathbf{x}_{i}\right)=f\left(\mathbf{x}_{i} \cdot \mathbf{w}\right)$。在逻辑回归中，激活函数被定义为逻辑函数$f(u)=\frac{1}{1+e^{-u}}$。如图1（a）所示，逻辑函数的两个尾部收敛于0和1。利用该激活函数，线性回归的原始成本函数不再是凸的，因此应用SGD可以给出局部最小值而不是全局最小值。因此，成本函数改变为交叉熵函数$C_{i}(\mathbf{w})=-y_{i} \log y_{i}^{*}-\left(1-y_{i}\right) \log \left(1-y_{i}^{*}\right)$和$C(\mathbf{w})=\frac{1}{n} \sum C_{i}(\mathbf{w})$，其中$y_{i}^{*}=f\left(\mathbf{x}_{i} \cdot \mathbf{w}\right)$。

用于逻辑回归的小批量SGD算法在每次迭代中更新系数，如下所示：
$$
\mathbf{w} :=\mathbf{w}-\frac{1}{|B|} \alpha \mathbf{X}_{B}^{T} \times\left(f\left(\mathbf{X}_{B} \times \mathbf{w}\right)-\mathbf{Y}_{B}\right) \tag{3}
$$
请注意，逻辑回归的向后传播与线性回归的形式完全相同，但它是使用不同的激活和成本函数导出的。Logistic回归的SGD唯一区别是在前向传播中对内积应用额外的逻辑函数。

#### 神经网络

神经网络是回归的推广，用于学习高维输入和输出数据之间更复杂的关系。它广泛应用于图像处理，语音和文本识别等广泛领域，经常在每个领域取得突破。图1（b）显示了具有$m-1​$个隐藏层的神经网络的示例。隐藏层和输出层中的每个节点是回归的实例，并且与激活函数和系数向量相关联。节点也称为神经元。流行的激活函数包括逻辑和RELU函数$(f(u)=\max (0, u))​$。

对于具有多个类的分类问题，通常softmax函数$f\left(u_{i}\right)=\frac{e^{-u_{i}}}{\sum_{i=1}^{d_{m}} e^{-u_{i}}}$应用于输出层，其中$d_m$表示输出层中神经元的总数。洞察力是softmax函数之后的输出始终是概率分布：每个输出介于0和1之间，所有输出总和为1。

为了使用SGD训练神经网络，在每次迭代中应用等式1以更新所有神经元的所有系数，其中每个神经元被处理类似于回归。特别地，令$di​$是层$i​$中的神经元的数量，并且$d0 = d​$是输入数据中的特征的数量。$d_m​$是输出的维度。我们将第$i​$层的系数矩阵表示为$d_{i-1} \times d_{i}​$矩阵$\mathbf{W}_{i}​$，并且将值表示为$| B |×d_i​$矩阵。$X_0​$初始化为$X_B​$。在每次迭代的前向传播中，第$i​$层的矩阵$X_i​$被计算为$\mathbf{X}_{i}=f\left(\mathbf{X}_{i-1} \times \mathbf{W}_{i}\right)​$。在后向传播中，给定诸如交叉熵函数的成本函数，每个神经元中的每个系数的更新函数可以以闭合形式表示。为了计算它，我们迭代地计算向量$\mathbf{Y}_{i}=\frac{\partial C(\mathbf{W})}{\partial \mathbf{U}_{i}}​$，其中$\mathbf{U}_{i}=\mathbf{X}_{i-1} \times \mathbf{W}_{i}​$。$\mathbf{Y}_{m}​$初始化为$\frac{\partial C}{\partial \mathbf{X}_{m}} \odot \frac{\partial f\left(\mathbf{U}_{m}\right)}{\partial \mathbf{U}_{m}}​$，其中$\frac{\partial f\left(\mathbf{U}_{m}\right)}{\partial \mathbf{U}_{m}}​$只是激活函数的衍生物，$\odot​$是元素明智的产品。通过连锁规则，$\mathbf{Y}_{i}=\left(\mathbf{Y}_{i+1} \times \mathbf{W}_{i}^{T}\right) \odot \frac{\partial f\left(\mathbf{U}_{i}\right)}{\partial \mathbf{U}_{i}}​$。最后，通过letting$\mathbf{W}_{i} :=\mathbf{W}_{i}-\frac{\alpha}{|B|} \cdot \mathbf{X}_{i} \times \mathbf{Y}_{i}​$更新系数。

**参数**：发件人$S​$和接收者$R​$。

**主函数**：在从$R​$输入$(SELECT，sid，b)​$和从$S​$输入$(SEND，sid，x0，x1)​$时，将$(RECV，sid，xb)​$返回到$R​$.

​										图2：$\mathcal{F}_{o t}$理想的功能

### 安全计算

**不经意的转移**。不经意传输$(OT)​$是一种基本的加密原语，通常用作MPC中的构建块。在不经意的传输协议中，发送方$S​$具有两个输入$x_0​$和$x_1​$，并且接收方$R​$具有选择位$b​$并且想要获得$x_b​$而不学习任何其他内容或者将$b​$显示为$S​$.图2描述了通过这样的方式实现的理想功能协议。我们使用符号$\left(\perp ; x_{b}\right) \leftarrow \mathrm{OT}\left(x_{0}, x_{1} ; b\right)​$来表示实现此功能的协议。

我们使用$OT​$作为我们的离线协议的一部分来生成乘法三元组，并在逻辑回归和神经网络训练的在线阶段使用OT来安全地计算激活函数。可以使用[38]的协议实现一轮$OT​$，但它需要双方的公钥操作。$OT​$扩展[26,10]通过允许发送器和接收器以$λ​$基本$OT​$（具有公钥操作）和$O(m)​$快速对称密钥的成本执行$m​$个$OT​$来最小化该成本，其中$λ​$是安全性参数。我们的实现利用$OT​$扩展来提高效率。我们还使用了一种称为相关$OT​$扩展的$OT​$扩展的特殊风格[10]。在我们用$COT​$表示的这个变体中，发送者对每个$OT​$的两个输入不是独立的。相反，每个$OT​$实例的两个输入是：随机值$s0​$和值$s_{1}=f\left(s_{0}\right)​$，用于发送者选择的相关函数f。由$COT_l​$表示的用于I比特消息的$COT​$的通信是$λ+ 1​$比特，并且计算由3个散列组成。

**乱码电路2PC**。[46]首先介绍了乱码电路。一种乱码方案包括一个带有随机种子$σ​$和函数$f​$的乱码算法，并产生一个乱码电路$F​$和一个解码表$dec​$; 编码算法取输入$x​$和种子$σ​$，生成乱码输入$\widehat{x}​$; 评估算法以$\widehat{x}​$和$F​$为输入，返回乱码输出$\widehat{z}​$; 最后，解码算法取解码表$dec​$和$\widehat{z}​$并返回$f(x)​$。我们要求花边方案满足[12]中规定的标准安全属性。

给定这样的乱码方案，可以如下设计安全的双方计算协议：Alice生成随机种子$σ$并运行函数$f$的乱码算法以获得乱码电路$GC$。她还使用$σ$和$x$对输入$\widehat{x}$进行编码，作为编码算法的输入。Alice将$GC$和$\widehat{x}$发送给Bob。对于$y$的每个比特，Bob使用不经意的传输获得他的编码（乱码）输入$\widehat{y}$。

> 虽然基于OT的编码不是乱码方案的必需属性，但是所有现有结构都允许这种交互编码。

然后，他在$GC$，$\widehat{x}$，$\widehat{y}$上运行评估算法，以获得乱码输出$\widehat{z}$。我们可以让Alice，Bob或两者通过相应地传送解码表来学习输出。上述协议安全地实现了理想的功能$F_f$，它简单地使各方输入并计算$f$。有关半诚实对手的更详细描述和证据，请参见[31]。在我们的协议中，我们用$\left(z_{a}, z_{b}\right) \leftarrow$ Garbled Circuit $(x ; y, f)$表示这个乱码电路$2PC$

**秘密共享和乘法三元组**。在我们的协议中，所有中间值都在两个服务器之间进行秘密共享。我们采用三种不同的共享方案：添加剂共享，布尔共享和$Yao$共享。我们简要回顾一下这些方案，但请参阅[17]了解更多细节。

为了相加地共享$\left(\operatorname{Shr}^{A}(\cdot)\right)​$一个$\ell​$位值a，第一方$P_0​$随机均匀地生成$a_{0} \in \mathbb{Z}_{2^{\ell}}​$并将发送第$a_{1}=a-a_{0} \bmod 2^{\ell}​$给第二方$P_1​$。我们用$\langle a\rangle_{0}^{A}=a_{0}​$表示第一方的份额，而$\langle a\rangle_{1}^{A}=a_{1}​$表示第二方的份额。为了便于组合，我们在协议描述中省略了模块化操作。在本文中，我们主要使用添加剂共享，并简称为$\langle\cdot\rangle​$。为了重建$\left(\operatorname{Rec}^{A}(\cdot, \cdot)\right)​$一个加性共享值$\langle a\rangle​$，$P_i​$将$\langle a\rangle_{i}​$发送给计算$\langle a\rangle_{0}+\langle a\rangle_{1}​$的$P_{1-i}​$。

给定两个共享值$\langle a\rangle​$和$\langle b\rangle​$，通过$P_i​$计算$\langle c\rangle_{i}=\langle a\rangle_{i}+\langle b\rangle_{i}​$ mod $2^{\ell}​$很容易非交互式地添加共享。我们重载加法运算以表示$\langle a\rangle+\langle b\rangle​$的加法协议。

为了增加$\left(\mathrm{Mul}^{A}(\cdot, \cdot)\right)$两个共享值$\langle a\rangle$和$\langle b\rangle$，我们利用Beaver的预先计算乘法三元组技术。让我们假设双方已经分享了$\langle u\rangle$，$\langle v\rangle$，$\langle z\rangle$，其中$u$，$v$是$\mathbb{Z}_{2}$ 和 $z=u v \bmod 2^{\ell}$中的均匀随机值。然后$P_i$计算$\langle e\rangle_{i}=\langle a\rangle_{i}-\langle u\rangle_{i}$ 和 $\langle f\rangle_{i}=\langle b\rangle_{i}-\langle v\rangle_{i}$。

布尔共享可以看作是$\mathbb{Z}_{2}$中的附加共享，因此上面讨论的所有协议都可以继续。特别是，加法运算由$XOR$运算$(\oplus)$代替，乘法由$AND$运算$(\mathrm{AND}(\cdot, \cdot))$代替。我们用$\langle a\rangle_{i}^{B}$表示$P_i$方在布尔共享中的份额。

最后，人们还可以将一个乱码电路协议想象为在姚明共享输入上运行以产生$Yao$的输出共享。特别地，在所有的乱码方案中，对于每个线$w$，加料器$(P0)$产生两个随机串$k_{0}^{w}, k_{1}^{w}$。当使用点对点置换技术[33]时，garbler还会生成随机置换位$r_w$并且设$K_{0}^{w}=k_{0}^{w} \| r_{w}$ 和 $K_{1}^{w}=k_{1}^{w} \|\left(1-r_{w}\right)$。然后使用连接的位来置换每个乱码真值表的行。$Yao$分享$a$是$\langle a\rangle_{0}^{Y}=K_{0}^{w}, K_{1}^{w}$和 $\langle a\rangle_{1}^{Y}=K_{a}^{w}$。为了重建共享价值，各方交换其分享。可以通过拼接/评估相应的门来执行$XOR$和$AND$操作。

要从$$Yao$$共享$\langle a\rangle_{0}^{Y}=K_{0}^{w}, K_{1}^{w}$ 和 $\langle a\rangle_{1}^{Y}=K_{a}^{w}$切换到布尔共享，$P_0$让$\langle a\rangle_{0}^{B}=K_{0}^{w}[0]$ 和 $P_{1}$ lets $\langle a\rangle_{1}^{B}=\langle a\rangle_{1}^{Y}[0]$。换句话说，在乱码方案中使用的置换比特可以用于免费切换到布尔共享。我们用$\mathrm{Y} 2 \mathrm{B}(\cdot, \cdot)$表示这个$Yao$到布尔的转换。我们注意到我们没有在协议描述中明确使用$Yao$共享，因为它将隐藏在乱码方案中，但明确使用$Y2B$转换将乱码输出转换为布尔共享。

## 安全模型

### 建模

我们考虑一组客户$C_1,....,C_m$谁想要在他们的联合数据上训练各种模型。我们不会对如何在客户端之间分配数据做出任何假设。特别地，数据可以是水平或垂直分区的，或者作为先前计算的一部分在它们之间秘密共享。

一种自然的解决方案是执行安全的多方计算，其中每个客户端扮演一方的角色。虽然这种方法满足了我们的目标隐私属性，它有几个缺点。首先，它要求客户参与整个协议。其次，与两方案例不同，超过两方（以及不诚实的大多数）的技术要贵得多，而且不能扩展到大输入大小或大量客户端。

因此，我们考虑服务器辅助设置，其中客户端将计算外包给两个不可信但非串通的服务器$S_0$和$S_1$。服务器辅助的MPC已经形式化并用于以前的各种工作中（例如见[28]）。它也被用于隐私保护机器学习的先前工作[36,35,20]。这种设置的两个重要优点是（i）客户可以在设置阶段在两台服务器之间分配（秘密共享）它们的输入，但不参与任何未来的计算，以及（ii）我们可以从高效的组合中受益用于布尔运算的技术，例如乱码电路和OT扩展，以及算术计算，例如离线/在线乘法三元组共享。

根据应用场景，以前的工作是指两个服务器作为评估者和加密服务提供者（$CSP$）[36]，或评估者和维护数据的云服务提供者[23]。这两个服务器也可以是客户的不同子集的代表，或者它们自己是拥有数据的客户端。无论分配给服务器的具体角色如何，信任模型都是相同的，并假设这两个服务器不受信任但不串通。我们接下来详细讨论安全性定义。

### 安全定义

回想一下，有关各方是客户$C_1,....,C_m​$和两个服务器$S_0​$，$S_1​$。我们假设一个半诚实的对手$A​$可以破坏客户端的任何子集，并且最多可以破坏两个服务器中的一个。这捕获了两个服务器没有串通的属性，即如果一个是由对手控制的，则第二个服务器表现得很诚实。请注意，我们不对客户端之间以及客户端与服务器之间的串通进行任何限制。我们称这样的对手为可接受的对手。在一个特定场景中（参见第5节），我们通过要求服务器不与客户端串通来削弱安全模型。

安全定义应该要求这样的对手只学习它已经损坏的客户端的数据和最终输出，而不是剩下的其他诚实客户数据。例如，攻击$C1​$，$C2​$和$S1​$的对手$A​$不应该在训练模型之外学习有关$C3​$数据的任何信息。我们使用$Universal Composition（UC）​$框架定义安全性[14]。我们在此简要介绍了该定义，但请参阅[14]了解详细信息。我们的协议的目标理想功能$\mathcal{F}_{m l}​$如图3所示。

$UC​$框架中的执行涉及（非均匀）交互式图灵机的集合。在这项工作中，我们考虑如上所述的可接受和半诚实的对手$A​$。双方根据协议交换消息。未损坏方的协议输入由环境机器选择。未受损害的各方也会向环境报告其协议输出。在交互结束时，环境输出一个位。攻击者还可以与环境任意交互 - 不失一般性，对手是虚拟对手，它只是将所有收到的协议消息转发到环境中，并按照环境的指示在协议中行动。

通过比较真实和理想的交互来定义安全性。令$real [Z，A，π，λ]$表示当与对手$A$和在安全参数$λ$上执行协议$π$的诚实方交互时环境$Z$的最终（单比特）输出。这种相互作用被称为涉及协议$π$的真实交互。

**参数**：客户$C_1 ,....,C_m​$和服务器$S_0​$，$S_1​$。

**上传数据**：在$C_i​$的输入$x_i​$上，在内部存储$x_i​$。

**计算**：在来自$S_0​$或$S_1​$的输入$f​$上，计算（$y_1,...,y_m​$）=$ f(x_1,...,x_m)​$并将$y_i​$发送到$C_i​$。该步骤可以使用不同的功能重复多次。

​									图3：理想功能$\mathcal{F}_{m l}​$

功能机器并转发功能对环境的响应。因此，可信任功能代表各方执行整个计算。协议的目标理想功能$\mathcal{F}_{m l}​$在图3中描述。让理想的$[Z，S，Fml，λ]​$表示与对手$S​$和在存在功能F时运行伪协议的诚实方交互时环境$Z​$的输出安全参数$λ​$。

我们说协议π**安全地实现**了功能$\mathcal{F}_{m l}$，如果对于每个可接受的对手$A$攻击真实的交互（不失一般性，我们可以将$A$作为虚拟对手），存在攻击者$S$（称为模拟器）攻击理想的相互作用，使得对于所有环境$Z$，以下数量可忽略不计（以$λ$为单位）：
$$
\left|\operatorname{Pr}[\operatorname{REAL}[\mathcal{Z}, \mathcal{A}, \pi, \lambda]=1]-\operatorname{Pr}\left[\operatorname{IDEAL}\left[\mathcal{Z}, \mathcal{S}, \mathcal{F}_{m l}, \lambda\right]=1\right]\right|
$$
直观地，模拟器必须在对手在真实交互中实现的理想交互中实现相同的效果（在环境上）。请注意，环境视图包括（不失一般性）诚实方发送给对手的所有消息以及诚实方的输出。

## 隐私保护机器学习

在本节中，我们将介绍使用$SGD​$进行隐私保护机器学习的协议。我们首先在4.1节中描述了一个线性回归协议，它仅基于算术秘密共享和乘法三元组。接下来，我们将讨论如何在4.2节中在离线阶段有效地生成这些乘法三元组。然后，我们概括了我们的技术，以支持4.3和4.4节中的逻辑回归和神经网络训练。最后，第4.5节介绍了支持预测，学习率调整和终止确定的技术。

### 隐私保护线性回归

回想一下，我们假设训练数据是在两个服务器$S0​$和$S1​$之间秘密共享的。我们用$\langle\mathbf{X}\rangle_{0}​$，$\langle\mathbf{Y}\rangle_{0}​$和$\langle\mathbf{X}\rangle_{1}​$，$\langle\mathbf{Y}\rangle_{1}​$表示份额。实际上，客户端可以在两个服务器之间分配共享，或者使用S0的公钥加密第一个共享，将第一个加密共享和第二个明文共享上传到$S1​$。$S1​$然后将加密的共享传递给$S_0​$以进行解密。在我们的协议中，我们还让系数$w​$在两个服务器之间秘密共享。只需将$\langle\mathbf{w}\rangle_{0}​$，$\langle\mathbf{w}\rangle_{1}​$设置为随机，即可在两个服务器之间无任何通信的情况下将其初始化为随机值。它在每次$SGD​$迭代后更新并保持秘密共享，直到重建结束。

如2.1节所述，线性回归的更新函数是$w_{j} :=w_{j}-\alpha\left(\sum_{k=1}^{d} x_{i k} w_{k}-\right.y_{i} ) x_{i j}$，仅由加法和乘法组成。因此，我们对秘密共享值应用相应的加法和乘法算法来更新系数，这是$\left\langle w_{j}\right\rangle :=\left\langle w_{j}\right\rangle-\alpha \mathrm{Mul}^{A}\left(\sum_{k=1}^{d} \mathrm{Mul}^{A}\left(\left\langle x_{i k}\right\rangle,\left\langle w_{k}\right\rangle\right)-\left\langle y_{i}\right\rangle,\left\langle x_{i j}\right\rangle\right)$。我们将协议分为两个阶段：在线和离线。在线阶段训练给定数据的模型，而离线阶段主要包括乘法三元组生成。我们将重点放在本节的在线阶段，并在4.2节讨论离线阶段。

**共享设置中的矢量化**。我们还希望受益于第2.1节中讨论的小批量和矢量化技术（见公式2）。为实现这一目标，我们将共享值的加法和乘法运算推广到共享矩阵。通过将$\operatorname{Shr}^{A}$应用于每个元素来共享矩阵。给定两个共享矩阵$\langle\mathbf{A}\rangle$和$\langle\mathbf{B}\rangle$，可以通过使$\langle\mathbf{C}\rangle_{i}=\langle\mathbf{A}\rangle_{i}+\langle\mathbf{B}\rangle_{i}$对于$i∈{0,1}$来非交互地计算矩阵加法。为了乘以两个共享矩阵，而不是使用独立的乘法三元组，我们采用共享矩阵$\langle\mathbf{U}\rangle$，$\langle\mathbf{V}\rangle$，$\langle\mathbf{Z}\rangle$，其中$U$和$V$中的每个元素在$\mathbb{Z}_{2^{l}}$中是均匀随机的，$U$具有与$A$相同的维度，$V$具有相同的维度因为$B$和$\mathbf{Z}=\mathbf{U} \times \mathbf{V} \bmod 2^{l}$。$S_i$计算$\langle\mathbf{E}\rangle_{i}=\langle\mathbf{A}\rangle_{i}-\langle\mathbf{U}\rangle_{i}$，$\langle\mathbf{F}\rangle_{i}=\langle\mathbf{B}\rangle_{i}-\langle\mathbf{V}\rangle_{i}$并将其发送到其他服务器。两个服务器重建$E$和$F$并设置$\langle\mathbf{C}\rangle_{i}=-i \cdot \mathbf{E} \times \mathbf{F}+\langle\mathbf{A}\rangle_{i} \times \mathbf{F}+\mathbf{E} \times\langle\mathbf{B}\rangle_{i}+\langle\mathbf{Z}\rangle_{i}$。这种推广的想法是矩阵$A$中的每个元素总是被$U$中的相同随机元素掩盖，而它在矩阵乘法中乘以$B$中的不同元素。我们的安全证明确认这不会影响协议的安全性，但由于矢量化，使协议显着提高效率。

将该技术应用于线性回归，在每次迭代中，我们假设一组小批量索引$B$是公共的，并执行更新$\langle\mathbf{w}\rangle :=\langle\mathbf{w}\rangle-\frac{1}{|B|} \alpha\left.\operatorname{Mul}^{A}\right.\left(\left\langle\mathbf{X}_{B}^{T}\right\rangle, \operatorname{Mul}^{A}\left(\left\langle\mathbf{X}_{B}\right\rangle,\langle\mathbf{w}\rangle\right)-\left\langle\mathbf{Y}_{B}\right\rangle\right)$

我们进一步观察到，一个数据样本将在不同的时期中使用多次，但它足以通过相同的随机乘法三元组来掩盖它。因此，在离线阶段，生成一个共享的$n×d$随机矩阵$\langle\mathbf{U}\rangle$以掩蔽数据样本$\langle\mathbf{X}\rangle$。在在线阶段的开始，计算并交换$\langle\mathbf{E}\rangle_{i}=\langle\mathbf{X}\rangle_{i}-\langle\mathbf{U}\rangle_{i}$以通过一次交互重建$E$之后，在每次迭代中，选择$E_B$并在乘法协议中使用，而无需任何进一步的计算和通信。特别是，在离线阶段，一系列的小批量指数$B_1,....,B_t$由两台服务器达成一致。这只需要知道$n，d，t$或上限，但不需要任何实际数据。然后乘法三元组$\langle\mathbf{U}\rangle$，$\langle\mathbf{V}\rangle$，$\langle\mathbf{Z}\rangle$，$\left\langle\mathbf{V}^{\prime}\right\rangle$，$\left\langle\mathbf{Z}^{\prime}\right\rangle$预先计算具有以下性质：$U$是用于掩盖数据$X$的$n×d$矩阵，$V$是一个$d×t$矩阵，其中每列用于在一次迭代（正向传播）中屏蔽$w$，并且$\mathbf{V}^{\prime}$是$|B| \times t$矩阵，其中每列用于在一次迭代（后向传播）中掩蔽差矢量$\mathbf{Y}^{*}-\mathbf{Y}$。然后，对于$i = 1$，我们让$\mathbf{Z}[i]=\mathbf{U}_{B_{i}} \times \mathbf{V}[i]$ and $\mathbf{Z}^{\prime}[i]=\mathbf{U}_{B_{i}}^{T} \times \mathbf{V}^{\prime}[i]$，其中$M [i]$表示矩阵$M$的第$i$列。使用矩阵形式的乘法三元组，在线和离线阶段的计算和通信都大大减少。我们会迟到分析成本。

我们用$\mathcal{F}_{\text { of fline }}$表示在离线阶段实现这些矩阵生成的理想功能。

**共享十进制数的算术运算**。如前所述，隐私保护线性回归的先前工作的低效率的主要来源源于对共享/加密十进制数的计算。先前的解决方案要么将十进制数视为整数，要么在乘法后使用非常大的有限域[21]保持完全准确性，或者利用$2PC​$用于布尔电路对十进制数执行定点[20]或浮点[34]乘法 。前者只能支持有限数量的乘法，因为结果的范围随着乘法的数量呈指数增长。这对于乘法次数较多的训练来说是禁止的。后者引入了高开销，因为用于乘以两个$l-bit​$的布尔电路具有$O\left(l^{2}\right)​$个门，并且对于每次执行的乘法，需要在$2PC​$（例如，Yao的乱码电路）中计算这样的电路。

我们提出了一个简单但有效的解决方案，以支持整数字段中的十进制算术。考虑两个十进制数$x​$和$y​$的定点乘法，小数部分中最多$l_D​$位。我们首先通过让$x^{\prime}=2^{l_{D}} x​$ 和 $y^{\prime}=2^{l_{D}} y​$将数字转换为整数，然后将它们相乘以获得乘积$z=x^{\prime} y^{\prime}​$。注意，$z​$最多有$2l_D​$位表示乘积的小数部分，因此我们简单地截断$z​$的最后$l_D​$位，使得它最多具有代表小数部分的$l_D​$位。从数学上讲，如果$z​$被分解为两个部分$z=z_{1} \cdot 2^{l_{D}}+z_{2}​$，其中$0 \leq z_{2}<2^{l_{D}}​$，则截断结果为$z_1​$。我们用$\lfloor z\rfloor​$表示这种截断操作。

我们表明，当$z$是秘密共享时，这种截断技术也有效。特别是，这两个服务器可以独立地截断它们各自的$z$共享。在下面的定理中，我们证明了对于足够大的场，这些截断的共享在重建时具有高概率，与期望的$\lfloor z\rfloor$最多相差1。换句话说，与标准定点算法相比，我们在小数部分的最低有效位中产生一个小误差。

我们还注意到，如果十进制数$z​$为负数，则它将在字段中表示为$2^{l}-|z|​$，其中$|z|​$是它的绝对值，截断操作变为$\lfloor z\rfloor= 2^{l}-\lfloor|z|\rfloor​$。我们证明了正数和负数的以下定理。

**定理1**。在字段$\mathbb{Z}_{2} \iota$中，令let $x \in\left[0,2^{l_{x}}\right] \cup\left[2^{l}-2^{l_{x}}, 2^{l}\right)$，其中$l>l_{x}+1$并且给定$x$的$\langle x\rangle_{0},\langle x\rangle_{1}$，令$\langle\lfloor x\rfloor\rangle_{0}=\left\lfloor\langle x\rangle_{0}\right\rfloor$ 和 $\langle\lfloor x\rfloor\rangle_{1}=2^{l}-\left\lfloor 2^{l}-\langle x\rangle_{1}\right\rfloor$。然后概率为$1-2^{l_{x}+1-l}$，$\operatorname{Rec}^{A}\left(\langle\lfloor x\rfloor\rangle_{0},\langle\lfloor x\rfloor\rangle_{1}\right) \in\{\lfloor x\rfloor- 1,\lfloor x\rfloor,\lfloor x\rfloor+ 1\}$，其中$\lfloor\cdot\rfloor$表示截断$l_{D} \leq l_{x}$ 位。

证明。设$\langle x\rangle_{0}=x+r \bmod 2^{l}$，其中$r$在$\mathbb{Z}_{2} \iota$中是均匀随机的，则$\langle x\rangle_{1}=2^{l}-r$。我们将$r$分解为$r_{1} \cdot 2^{l_{D}}+r_{2}$，其中$0 \leq r_{2}<2^{l_{D}}$且$0 \leq r_{1}<2^{l-l_{D}}$。我们证明如果$2^{l_{x}} \leq r<2^{l}-2^{l_{x}}$，$\operatorname{Rec}^{A}\left(\langle\lfloor x\rfloor\rangle_{0},\langle\lfloor x\rfloor\rangle_{1}\right) \in\{\lfloor x\rfloor- 1,\lfloor x\rfloor,\lfloor x\rfloor+ 1\}$。考虑以下两种情况。

​	情况1：如果$0 \leq x \leq 2^{l_{x}}​$，那么$0 \leq x+r<2^{l}​$ 且 $\langle x\rangle_{0}=x+r​$，没有模数。令$x=x_{1} \cdot 2^{l_{D}}+x_{2}​$，其中$0 \leq x_{2}<2^{l_{D}}​$ 且 $0 \leq x_{1}<2^{l_{x}-l_{D}}​$。然后我们得到$x+r=\left(x_{1}+r_{1}\right) \cdot 2^{l_{D}}+\left(x_{2}+r_{2}\right)=\left(x_{1}+r_{1}+c\right) \cdot 2^{l_{D}}+\left(x_{2}+r_{2}-c \cdot 2^{l_{D}}\right)​$，其中，如果$x_{2}+r_{2}<2^{l_{D}}​$，则进位$c = 0​$，否则$c = 1​$。截断后，$\langle\lfloor x\rfloor\rangle_{0}=\lfloor x+r\rfloor= x_{1}+r_{1}+c​$ 和 $\langle\lfloor x\rfloor\rangle_{1}=2^{l}-r_{1}​$。因此，$\operatorname{Rec}^{A}\left(\langle\lfloor x\rfloor\rangle_{0},\langle\lfloor x\rfloor\rangle_{1}\right)=x_{1}+c=\lfloor x\rfloor+ c​$。

​	情况2：如果$2^{l}-2^{l x} \leq x<2^{l}$，则$x+r \geq 2^{l}$ 且 $\langle x\rangle_{0}=x+r-2^{l}$。设$x=2^{l}-x_{1} \cdot 2^{l_{D}}-x_{2}$，其中$0 \leq x_{2}<2^{l_{D}}$ 并 $0 \leq x_{1}<2^{l_{x}-l_{D}}$。我们有$x+r-2^{l}=\left(r_{1}-x_{1}\right) \cdot 2^{l_{D}}+\left(r_{2}-x_{2}\right)=\left(r_{1}-x_{1}-c\right) \cdot 2^{l_{D}}+\left(r_{2}-x_{2}+c \cdot 2^{l_{D}}\right)$，其中进位 如果r2> x2则$c = 0$，否则$c = 1$。截断后，$\langle\lfloor x\rfloor\rangle_{0}=\left\lfloor x+r-2^{l}\right\rfloor= r_{1}-x_{1}-c$ 和$\langle\lfloor x\rfloor\rangle_{1}=2^{l}-r_{1}$。因此，$\operatorname{Rec}^{A}\left(\langle\lfloor x\rfloor\rangle_{0},\langle\lfloor x\rfloor\rangle_{1}\right)=2^{l}-x_{1}-c=\lfloor x\rfloor- c$。

最后，我们的假设成立的概率，即随机$r​$在$\left[2^{l_{x}}, 2^{l}-2^{l_{x}}\right)​$范围内的概率是$1-2^{l_{x}+1-l}​$。

通过在证明中用$p$替换$2^{l}$，定理1可以以自然方式扩展到素数域$\mathbb{Z}_{p}$。我们还注意到截断不会影响秘密共享的安全性，因为共享会在没有任何交互的情况下独立地截断共享。

****

**协议**SGD线性$\left(\langle\mathbf{X}\rangle,\langle\mathbf{Y}\rangle,\langle\mathbf{U}\rangle,\langle\mathbf{V}\rangle,\langle\mathbf{Z}\rangle,\left\langle\mathbf{V}^{\prime}\right\rangle,\left\langle\mathbf{Z}^{\prime}\right\rangle\right)$:

***

1. $S_i$计算$\langle\mathbf{E}\rangle_{i}=\langle\mathbf{X}\rangle_{i}-\langle\mathbf{U}\rangle_{i}$ for $i \in\{0,1\}$。然后各方运行$\operatorname{Rec}\left(\langle\mathbf{E}\rangle_{0},\langle\mathbf{E}\rangle_{1}\right)$以获得$\mathbf{E}$。
2. **for** j = 1, . . . , t **do**
3. ​	缔约方选择小批量$\left\langle\mathbf{X}_{B_{j}}\right\rangle,\left\langle\mathbf{Y}_{B_{j}}\right\rangle​$。
4. ​	$S_i​$计算$\left\langle\mathbf{F}_{j}\right\rangle_{i}=\langle\mathbf{w}\rangle_{i}-\langle\mathbf{V}[j]\rangle​$，其中$i \in\{0,1\}​$。然后派对运行$\operatorname{Rec}\left(\left\langle\mathbf{F}_{j}\right\rangle_{0},\left\langle\mathbf{F}_{j}\right\rangle_{1}\right)​$以恢复$\mathbf{F}_{j}​$
5. ​	$S_i​$计算$\left\langle\mathbf{Y}_{B_{j}}^{*}\right\rangle_{i}=-i \cdot \mathbf{E}_{B_{j}} \times \mathbf{F}_{i}+\left\langle\mathbf{X}_{B_{j}}\right\rangle_{i} \times \mathbf{F}_{i}+\mathbf{E}_{B_{j}} \times\langle\mathbf{w}\rangle_{i}+\left\langle\mathbf{Z}_{j}\right\rangle_{i}​$，其中$i \in\{0,1\}​$。
6. ​	$S_i​$计算差值$\left\langle\mathbf{D}_{B_{j}}\right\rangle_{i}=\left\langle\mathbf{Y}_{B_{j}}^{*}\right\rangle_{i}-\left\langle\mathbf{Y}_{B_{j}}\right\rangle_{i}​$，其中$i \in\{0,1\}​$。
7. ​	$S_i$计算$\left\langle\mathbf{F}_{j}^{\prime}\right\rangle_{i}=\left\langle\mathbf{D}_{B_{j}}\right\rangle_{i}-\left\langle\mathbf{V}_{j}^{\prime}\right\rangle_{i}$，其中$i \in\{0,1\}$。然后，各方运行$\operatorname{Rec}\left(\left\langle\mathbf{F}_{j}^{\prime}\right\rangle_{0},\left\langle\mathbf{F}_{j}^{\prime}\right\rangle_{1}\right)$以获得$\mathbf{F}_{j}^{\prime}$。
8. ​	$S_i​$计算$\langle\boldsymbol{\Delta}\rangle_{i}=-i \cdot \mathbf{E}_{B_{j}}^{T} \times \mathbf{F}_{j}^{\prime}+\left\langle\mathbf{X}_{B_{j}}^{T}\right\rangle_{i} \times \mathbf{F}_{j}^{\prime}+\mathbf{E}_{B_{j}}^{T} \times\left\langle\mathbf{D}_{B_{j}}\right\rangle_{i}+\left\langle\mathbf{Z}_{j}^{\prime}\right\rangle_{i}​$对于$i \in\{0,1\}​$。
9. ​	$S_i$截断其$\Delta$元素的份额以获得$\left\lfloor\langle\Delta\rangle_{i}\right\rfloor$。
10. ​	$S_i$计算$\langle\mathbf{w}\rangle_{i} :=\langle\mathbf{w}\rangle_{i}-\frac{\alpha}{|B|}\left\lfloor\langle\Delta\rangle_{i}\right\rfloor$对于$i \in\{0,1\}​$。
11. 缔约方运行$\operatorname{Rec}^{A}\left(\langle\mathbf{w}\rangle_{0},\langle\mathbf{w}\rangle_{1}\right)$并输出$w$。

***

两个服务器之间用于隐私保护线性回归的在线阶段的完整协议如图4所示。它假设数据无关的共享矩阵$\langle\mathbf{U}\rangle,\langle\mathbf{V}\rangle,\langle\mathbf{Z}\rangle,\left\langle\mathbf{V}^{\prime}\right\rangle,\left\langle\mathbf{Z}^{\prime}\right\rangle​$已经在离线阶段生成。除了乘法和加法共享十进制数之外，该协议还要求在每次迭代中将系数向量乘以$\frac{\alpha}{|B|}​$。为了使该操作有效，我们设置$\frac{\alpha}{|B|}​$ 为2的幂，即$\frac{\alpha}{|B|}​$ = $2^{-k}​$。然后乘以$\frac{\alpha}{|B|}​$ 可以通过让各方从其系数的份额中截断$k​$个附加位来代替。

我们概述了以下关于在线协议安全性的定理的证明。

**定理2**。考虑一种协议，其中客户端在运行图4协议的两个服务器之间分配其数据的算术份额，并将输出发送给客户端。在$\mathcal{F}_{\text { of fline }}​$混合模型中，该协议实现了图3中用于线性回归函数的理想函数$\mathcal{F}_{m l}​$，存在半诚实的可接受对手（参见第3节）。

草图。我们模型中的可接受对手可能会破坏一个服务器和客户端的任何子集。鉴于协议相对于两个服务器是对称的，我们只需要考虑对手破坏$S_0$和除了一个客户端之外的所有客户端的情况，即。$\mathcal{C}_{1}, \ldots, \mathcal{C}_{m-1}$。

我们描述了一个模拟器$S$，模拟了理想世界中的上述对手。$S$将损坏的客户端输入数据提交给功能，并接收线性回归的最终输出，即系数$w​$的最终值。

$S$然后运行$A$。代表诚实的客户端S在该客户端持有的每个值中将$\mathbb{Z}_{2^l}$中的随机共享发送给$\mathcal{A}$.这是客户参与的唯一消息。在协议的其余部分中，生成对应于诚实服务器的$\langle\mathbf{X}\rangle,\langle\mathbf{Y}\rangle,\langle\mathbf{U}\rangle,\langle\mathbf{V}\rangle,\langle\mathbf{Z}\rangle,\left\langle\mathbf{V}^{\prime}\right\rangle,\left\langle\mathbf{Z}^{\prime}\right\rangle$的共享的随机矩阵和向量，并使用这些来发挥与$\mathcal{A}$交互的诚实服务器的角色随机生成的值。

最后，在要恢复$w$的最后一步中，$S$调整诚实服务器的$w$份额，使得恢复的值确实是它从功能中接收的系数向量。
这结束了模拟。

![Edjzw9.png](https://s2.ax1x.com/2019/05/04/Edjzw9.png)

图5：隐私保护线性回归与十进制数截断和明文训练的准确性比较。（a）MNIST数据集，$|B|=128$，（b）Arcene数据集，$|B|=32$。

我们简单地论证$A$在真实世界和理想世界中的观点，因此，环境在两个世界中的观点是难以区分的。这紧跟在算术秘密共享的安全性以及在离线阶段中生成的矩阵/向量确实是随机的这一事实之后。特别是，在协议中发送和接收并重建的所有消息（除了$w$之外，都是使用上述真实协议和模拟中的均匀随机共享生成的，因此实际上视图都是相同分布的。这就是我们的论点。

我们注意到这个论点隐含地解释了为什么使用一个掩码矩阵$U$足以隐藏数据矩阵$X$.原因是攻击者只能在第一次交互中看到掩码值一次，而在$X$上的其余计算就会发生没有诚实和损坏的服务器之间的交互。

