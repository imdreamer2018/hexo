title: 可扩展隐私保护机器学习系统
author: 追梦人

toc: true

tags:

  - MachineLearning
  - Privacy-Preserving
  - Cryptology
categories: []
date: 2019-05-03 21:23:00

---

# 可扩展隐私保护机器学习系统

本文来自Yupeng Zhang在2017年信息安全旗舰会议《Security & Privacy》上的论文演讲，论文的题目是《安全机器学习：可扩展隐私保护机器学习系统》（SecureML: A System for Scalable Privacy-Preserving Machine Learning）。

论文链接：[Cryptology ePrint Archive: Report 2017/396](https://link.zhihu.com/?target=https%3A//eprint.iacr.org/2017/396)

以下是翻译后的原文。

<!-- more -->

## 摘要

机器学习在实践中被广泛用于为诸如图像处理，语音和文本识别的应用产生预测模型。在对从不同来源收集的大量数据进行培训时，这些模型更加准确。但是，海量数据收集引发了隐私问题。

在本文中，我们提出了新的和有效的隐私保护机器学习协议，用于线性回归，逻辑回归和使用随机梯度下降法的神经网络训练。我们的协议属于双服务器模型，其中数据所有者在两个非串通服务器之间分发其私有数据，这两个服务器使用安全的双方计算（2PC）在联合数据上训练各种模型。我们开发新技术以支持对共享十进制数的安全算术运算，并提出MPC友好的替代非线性函数，如sigmoid和softmax，它们优于以前的工作。

我们用C ++实现我们的系统。我们的实验证实，我们的协议比隐私保护线性和逻辑回归的现有技术实现快几个数量级，并且可以扩展到具有数千个特征的数百万个数据样本。我们还实施了第一个用于训练神经网络的隐私保护系统。

## 介绍

机器学习技术在实践中被广泛用于产生用于医学，银行业务，推荐服务，威胁分析和认证技术的预测模型。随着时间的推移收集的大量数据为旧问题提供了新的解决方案，深度学习的进步带来了语音，图像和文本识别方面的突破。

大型互联网公司收集用户的在线活动，以培训预测他们未来兴趣的推荐系统。来自不同医院和政府组织的健康数据可用于产生新的诊断模型，而金融公司和支付网络可以结合交易历史，商家数据和账户持有者信息来训练更准确的欺诈检测引擎。

虽然最近的技术进步使得能够更有效地存储，处理和计算大数据，但是组合来自不同来源的数据仍然是一项重要的挑战。竞争优势，隐私问题和法规以及围绕数据主权和管辖权的问题阻止了许多组织公开共享其数据。通过安全多方计算（MPC）进行隐私保护机器学习，通过允许不同实体在其联合数据上训练各种模型而不泄露结果之外的任何信息，提供了一种有前景的解决方案。

我们专注于训练线性回归，逻辑回归和神经网络模型的机器学习算法，并采用双服务器模型（更多细节见第3节），以前通过MPC保护隐私机器的工作常用[36，35,20]。在此模型中，在设置阶段，数据所有者（客户端）在两个非串通服务器之间处理，加密和/或秘密共享其数据。在计算阶段，两个服务器可以在客户的联合数据上训练各种模型，而无需学习训练模型之外的任何信息。

保护隐私线性回归[36,20]的现有技术解决方案比明文训练慢许多个数量级。先前实现中的低效率的主要来源是用于训练的大量计算发生在用于布尔电路的安全2PC内（例如，Yao的乱码电路），其对表示为整数的十进制数执行算术运算。
众所周知，布尔电路不适合执行算术运算，但鉴于现有的定点或浮点乘法技术需要使用布尔电路最有效的位级操作，它们似乎是不可避免的。

在逻辑回归和神经网络的情况下，问题甚至更具挑战性，因为训练过程计算许多非线性激活函数的实例，例如在2PC内计算昂贵的sigmoid和softmax。实际上，我们不知道这两种训练算法的任何隐私保护实现。

## 我们的贡献

我们在上面讨论的双服务器模型中设计了用于隐私保护线性回归，逻辑回归和神经网络训练的新的有效协议，假设跨客户端对数据集进行任意划分。

我们的隐私保护线性回归协议比针对同一问题的现有技术解决方案高几个数量级。例如，对于具有100,000个样本和500个特征的数据集，并且在可比较的设置和实验环境中，我们的协议比[36,20]中实现的协议快1100-1300倍。此外，正如我们的实验所示，我们显着缩小了隐私保护和明文训练之间的差距。

我们还实现了第一个用于逻辑回归和神经网络训练的隐私保护协议，效率很高。例如，在大小为60,000且具有784个特征的数据集上，我们的隐私保护逻辑回归的总运行时间为29秒，而我们用于训练具有3层和266个神经元的神经网络的隐私保护协议在21,000s中运行。

我们的协议自然分为数据无关的离线阶段和更快的在线阶段。当排除离线阶段时，协议在明文培训方面更具竞争力。例如，对于具有60,000个样本和784个特征的数据集，并且在LAN设置中，线性回归协议在1.4s中运行，逻辑回归在8.9s中运行，神经网络训练在653.0s中运行。

**对共享十进制数的算术**。如前所述，先前工作的一个主要瓶颈是在安全2PC内部计算定点算术，例如乱码电路。考虑到训练所需的大量乘法，这非常昂贵。

定点加法相当简单。对于乘法，我们证明以下策略非常有效：将两个共享十进制数表示为有限域中的共享整数;使用离线生成的乘法三元组对共享整数执行乘法运算;让每一方截断其产品的份额，以便固定数量的位代表小数部分。我们证明，与定点算法相比，在从这些截断的份额重建时，产品的概率很高，在分数部分的最低有效位置最多为1位。我们对两个不同数据集MNIST和Arcene [6,1]的实验证实，当表示小数部分的位数时，小截断误差对训练模型的准确性没有影响（实际上精度与标准训练的准确度相匹配）足够大。因此，隐私保护线性回归的在线阶段不涉及任何加密操作，仅包括整数乘法和位移，而离线阶段包括生成必要的乘法三元组。我们的微基准测试表明，即使在考虑总时间（在线和离线组合）时，与使用乱码电路的定点乘法相比，我们的方法产生了4-8倍的改善。

**MPC友好的激活功能**。如前所述，逻辑回归和神经网络训练需要计算逻辑
$$
\left(\frac{1}{1+e^{-x}}\right)
$$
和softmax
$$
\left(\frac{e^{-x_{i}}}{\sum e^{-x_{i}}}\right)
$$
函数，这些函数在共享值上计算起来很昂贵。我们通过实验证明，使用低次多项式逼近逻辑函数是无效的。特别地，需要程度至少为10的多项式来使用逻辑函数来接近训练的准确性。我们提出了一种新的激活函数，它可以看作是两个RELU函数的总和（见图7），并使用一个小的乱码电路有效地计算。类似地，我们用RELU函数，添加和单个分区的组合替换softmax函数。我们使用MNIST和Arcene数据集的实验证实，使用这些新函数生成的模型的准确性与使用原始函数训练的模型匹配或非常接近。

然后，我们提出了一种用于在算术共享和Yao共享之间切换的定制解决方案，并且对于我们的特定计算，我们提出了通过最小化交互轮次和调用的不经意传输（OT）的数量来显着降低成本。我们在6.5节中的微基准测试表明，评估我们的新函数的时间比用高次多项式逼近逻辑函数要快得多。

我们使用相同的思想来安全地评估神经网络训练中使用的RELU函数。

**矢量化协议**。矢量化，即在矩阵和矢量上操作，对于明文训练的效率是至关重要的。我们将展示如何从共享设置中的相同矢量化技术中受益。例如，在我们的协议的离线阶段，包括生成许多乘法三元组，我们提出并实现两个基于线性同态加密（LHE）和不经意传输的解决方案。这些技术受到先前工作的启发（例如，[17]），但针对我们需要计算共享矩阵和向量的乘法的矢量化场景进行了优化。因此，我们的离线协议的复杂性比为每次乘法生成独立乘法三元组的简单方法要好得多。特别是，基于OT的乘法三元组生成的性能提高了4倍，基于LHE的生成提高了41-66倍。

在类似于[20]的不同安全模型中，我们还提出了一个更快的离线阶段，客户端可以帮助生成乘法三元组。这提供了比我们的标准设置更弱的安全性。特别是，它需要额外的假设，即服务器和客户端不会串通，即攻击者破坏服务器或客户端子集，但不会破坏两者。我们讨论了这种方法的优缺点，并将其性能与第5节中的标准方法进行了比较。

